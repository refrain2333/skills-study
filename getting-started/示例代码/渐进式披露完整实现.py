"""
æ¸è¿›å¼æŠ«éœ²ï¼ˆProgressive Disclosureï¼‰å®Œæ•´å®ç°

æ¼”ç¤ºå¦‚ä½•åœ¨æœ‰å¤§é‡ skills çš„æƒ…å†µä¸‹é«˜æ•ˆåœ°åŠ è½½å†…å®¹ã€‚
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional
import time
from dataclasses import dataclass


# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šSkill å…ƒæ•°æ®å®šä¹‰
# ============================================================================

@dataclass
class SkillMetadata:
    """Skill å…ƒæ•°æ®ï¼ˆè½»é‡çº§ï¼Œç”¨äºå¿«é€ŸåŠ è½½ï¼‰"""
    id: str
    name: str
    description: str
    category: str
    tags: List[str]
    file_path: str
    size_bytes: int
    estimated_tokens: int
    prerequisites: List[str]
    related: List[str]


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ¸è¿›å¼åŠ è½½å™¨
# ============================================================================

class ProgressiveSkillLoader:
    """
    æ¸è¿›å¼ skill åŠ è½½å™¨
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. å¯åŠ¨æ—¶åªåŠ è½½å…ƒæ•°æ®ï¼ˆ< 100KBï¼‰
    2. éœ€è¦æ—¶æŒ‰éœ€åŠ è½½å®Œæ•´å†…å®¹
    3. æ”¯æŒç¼“å­˜é¿å…é‡å¤åŠ è½½
    """
    
    def __init__(self, skills_dir: str):
        self.skills_dir = Path(skills_dir)
        self.metadata: Dict[str, SkillMetadata] = {}
        self.loaded_content: Dict[str, str] = {}
        self.access_log = []  # è®°å½•è®¿é—®å†å²
    
    def initialize(self) -> Dict:
        """
        åˆå§‹åŒ–ï¼šç”Ÿæˆå’ŒåŠ è½½å…ƒæ•°æ®
        è¿™åªéœ€è¦æ‰§è¡Œä¸€æ¬¡ï¼Œéå¸¸å¿«
        """
        print("ğŸ“š åˆå§‹åŒ– Skill åŠ è½½å™¨...")
        start = time.time()
        
        # åˆ›å»ºç¤ºä¾‹ skills å…ƒæ•°æ®
        self.metadata = self._create_sample_metadata()
        
        elapsed = time.time() - start
        print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œç”¨æ—¶ {elapsed*1000:.1f}ms")
        print(f"   åŠ è½½äº† {len(self.metadata)} ä¸ª skill çš„å…ƒæ•°æ®\n")
        
        return {
            "total_skills": len(self.metadata),
            "init_time_ms": elapsed * 1000,
            "total_metadata_size_kb": sum(
                s.estimated_tokens for s in self.metadata.values()
            ) / 1000
        }
    
    def list_skills(self) -> Dict[str, str]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨ skillsï¼ˆåŸºäºå…ƒæ•°æ®ï¼‰
        æ‰§è¡Œé€Ÿåº¦ï¼š< 1ms
        """
        print("ğŸ“‹ åˆ—å‡ºæ‰€æœ‰ skills...")
        
        result = {}
        for skill_id, meta in self.metadata.items():
            result[skill_id] = {
                "name": meta.name,
                "description": meta.description,
                "category": meta.category,
                "estimated_tokens": meta.estimated_tokens
            }
        
        return result
    
    def search_skills(self, query: str) -> Dict[str, Dict]:
        """
        æœç´¢ skillsï¼ˆåŸºäºå…ƒæ•°æ®ï¼Œæå¿«ï¼‰
        æ‰§è¡Œé€Ÿåº¦ï¼š< 10ms
        """
        print(f"ğŸ” æœç´¢ skills: '{query}'...")
        start = time.time()
        
        query_lower = query.lower()
        results = {}
        
        for skill_id, meta in self.metadata.items():
            # åœ¨å¤šä¸ªå­—æ®µä¸­æœç´¢
            if (query_lower in meta.name.lower() or
                query_lower in meta.description.lower() or
                any(query_lower in tag.lower() for tag in meta.tags)):
                
                results[skill_id] = {
                    "name": meta.name,
                    "description": meta.description,
                    "tokens": meta.estimated_tokens
                }
        
        elapsed = (time.time() - start) * 1000
        print(f"   æ‰¾åˆ° {len(results)} ä¸ªç»“æœï¼Œç”¨æ—¶ {elapsed:.1f}ms\n")
        
        return results
    
    def get_skill_preview(self, skill_id: str, max_length: int = 200) -> Optional[str]:
        """
        è·å– skill çš„é¢„è§ˆï¼ˆä¸åŠ è½½å®Œæ•´å†…å®¹ï¼‰
        æ‰§è¡Œé€Ÿåº¦ï¼š< 1ms
        """
        if skill_id not in self.metadata:
            return None
        
        meta = self.metadata[skill_id]
        # ç›´æ¥ä»å…ƒæ•°æ®è¿”å›æè¿°ä½œä¸ºé¢„è§ˆ
        preview = meta.description
        if len(preview) > max_length:
            preview = preview[:max_length] + "..."
        
        return preview
    
    def load_full_skill(self, skill_id: str) -> Optional[str]:
        """
        æŒ‰éœ€åŠ è½½å®Œæ•´ skill å†…å®¹
        
        æ‰§è¡Œæµç¨‹ï¼š
        1. æ£€æŸ¥ç¼“å­˜ï¼ˆ< 1msï¼‰
        2. å¦‚æœæœªç¼“å­˜ï¼Œä»æ–‡ä»¶åŠ è½½ï¼ˆ~ 100msï¼‰
        3. ç¼“å­˜ç»“æœ
        
        ç¬¬ä¸€æ¬¡åŠ è½½ï¼š~ 100ms
        åç»­åŠ è½½ï¼š< 1msï¼ˆä»ç¼“å­˜ï¼‰
        """
        # ç¬¬1æ­¥ï¼šæ£€æŸ¥ç¼“å­˜
        if skill_id in self.loaded_content:
            return self.loaded_content[skill_id]
        
        # ç¬¬2æ­¥ï¼šæ£€æŸ¥å…ƒæ•°æ®
        if skill_id not in self.metadata:
            return None
        
        print(f"ğŸ“¥ åŠ è½½å®Œæ•´ skill: {skill_id}...")
        start = time.time()
        
        # ç¬¬3æ­¥ï¼šæ¨¡æ‹ŸåŠ è½½æ–‡ä»¶
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè¯»å–çœŸå®çš„ SKILL.md æ–‡ä»¶
        content = self._generate_sample_content(skill_id)
        
        # ç¬¬4æ­¥ï¼šç¼“å­˜
        self.loaded_content[skill_id] = content
        
        # ç¬¬5æ­¥ï¼šè®°å½•è®¿é—®
        elapsed = time.time() - start
        self.access_log.append({
            'skill_id': skill_id,
            'timestamp': time.time(),
            'load_time_ms': elapsed * 1000
        })
        
        print(f"   âœ… åŠ è½½å®Œæˆï¼Œç”¨æ—¶ {elapsed*1000:.1f}ms")
        print(f"   å¤§å°: {len(content)} å­—ç¬¦\n")
        
        return content
    
    def get_prerequisites(self, skill_id: str) -> List[str]:
        """è·å– skill çš„å‰ç½®è¦æ±‚ï¼ˆåŸºäºå…ƒæ•°æ®ï¼‰"""
        if skill_id not in self.metadata:
            return []
        
        return self.metadata[skill_id].prerequisites
    
    def get_related_skills(self, skill_id: str) -> List[str]:
        """è·å–ç›¸å…³ skillsï¼ˆåŸºäºå…ƒæ•°æ®ï¼‰"""
        if skill_id not in self.metadata:
            return []
        
        return self.metadata[skill_id].related
    
    def preload_skills(self, skill_ids: List[str]):
        """é¢„åŠ è½½å¤šä¸ª skills"""
        print(f"ğŸš€ é¢„åŠ è½½ {len(skill_ids)} ä¸ª skills...")
        
        for skill_id in skill_ids:
            self.load_full_skill(skill_id)
    
    def get_load_statistics(self) -> Dict:
        """è·å–åŠ è½½ç»Ÿè®¡"""
        return {
            "total_skills": len(self.metadata),
            "loaded_skills": len(self.loaded_content),
            "cache_size_bytes": sum(
                len(content) for content in self.loaded_content.values()
            ),
            "access_count": len(self.access_log),
            "total_load_time_ms": sum(
                log['load_time_ms'] for log in self.access_log
            )
        }
    
    # ========================================================================
    # ç§æœ‰æ–¹æ³•
    # ========================================================================
    
    def _create_sample_metadata(self) -> Dict[str, SkillMetadata]:
        """åˆ›å»ºç¤ºä¾‹ skills å…ƒæ•°æ®"""
        skills = [
            SkillMetadata(
                id="context-fundamentals",
                name="ä¸Šä¸‹æ–‡å·¥ç¨‹åŸºç¡€",
                description="ç†è§£ä¸Šä¸‹æ–‡çª—å£ã€æ³¨æ„åŠ›é¢„ç®—å’Œä¸Šä¸‹æ–‡è´¨é‡çš„é‡è¦æ€§",
                category="foundational",
                tags=["context", "fundamentals", "attention"],
                file_path="context-fundamentals/SKILL.md",
                size_bytes=12500,
                estimated_tokens=2500,
                prerequisites=[],
                related=["context-degradation", "context-compression"]
            ),
            
            SkillMetadata(
                id="multi-agent-patterns",
                name="å¤šä»£ç†æ¶æ„æ¨¡å¼",
                description="è®¾è®¡ç›‘ç£è€…ã€å¯¹ç­‰å’Œåˆ†å±‚ç­‰å¤šä»£ç†ç³»ç»Ÿæ¶æ„",
                category="architectural",
                tags=["multi-agent", "coordination", "patterns"],
                file_path="multi-agent-patterns/SKILL.md",
                size_bytes=18000,
                estimated_tokens=3600,
                prerequisites=["context-fundamentals"],
                related=["tool-design", "memory-systems"]
            ),
            
            SkillMetadata(
                id="context-degradation",
                name="ä¸Šä¸‹æ–‡å¤±è´¥æ¨¡å¼",
                description="è¯†åˆ«å¹¶å¤„ç†ä¸¢å¤±ä¸­é—´ã€ä¸­æ¯’ã€å¹²æ‰°ç­‰ä¸Šä¸‹æ–‡å¤±è´¥æƒ…å†µ",
                category="foundational",
                tags=["context", "degradation", "failure"],
                file_path="context-degradation/SKILL.md",
                size_bytes=10000,
                estimated_tokens=2000,
                prerequisites=["context-fundamentals"],
                related=["context-compression"]
            ),
            
            SkillMetadata(
                id="tool-design",
                name="å·¥å…·è®¾è®¡æœ€ä½³å®è·µ",
                description="è®¾è®¡ä»£ç†èƒ½æœ‰æ•ˆä½¿ç”¨çš„å·¥å…·å’Œæ¥å£",
                category="architectural",
                tags=["tools", "design", "interfaces"],
                file_path="tool-design/SKILL.md",
                size_bytes=15000,
                estimated_tokens=3000,
                prerequisites=["context-fundamentals"],
                related=["multi-agent-patterns"]
            ),
            
            SkillMetadata(
                id="memory-systems",
                name="å†…å­˜ç³»ç»Ÿè®¾è®¡",
                description="ä»å‘é‡å­˜å‚¨åˆ°çŸ¥è¯†å›¾çš„å†…å­˜æ¶æ„é€‰æ‹©å’Œå®ç°",
                category="architectural",
                tags=["memory", "storage", "retrieval"],
                file_path="memory-systems/SKILL.md",
                size_bytes=16000,
                estimated_tokens=3200,
                prerequisites=["context-fundamentals"],
                related=["multi-agent-patterns"]
            ),
            
            SkillMetadata(
                id="context-compression",
                name="ä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥",
                description="è®¾è®¡æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡å‹ç¼©æ–¹æ¡ˆä»¥å¤„ç†é•¿ä¼šè¯",
                category="operational",
                tags=["compression", "optimization", "efficiency"],
                file_path="context-compression/SKILL.md",
                size_bytes=14000,
                estimated_tokens=2800,
                prerequisites=["context-fundamentals", "context-degradation"],
                related=["context-optimization"]
            ),
            
            SkillMetadata(
                id="evaluation",
                name="è¯„ä¼°æ¡†æ¶",
                description="æ„å»ºå¤šç»´è¯„ä¼°æ¡†æ¶è¯„ä¼°ä»£ç†ç³»ç»Ÿè´¨é‡",
                category="operational",
                tags=["evaluation", "metrics", "quality"],
                file_path="evaluation/SKILL.md",
                size_bytes=12000,
                estimated_tokens=2400,
                prerequisites=[],
                related=["advanced-evaluation"]
            ),
        ]
        
        return {skill.id: skill for skill in skills}
    
    def _generate_sample_content(self, skill_id: str) -> str:
        """ç”Ÿæˆç¤ºä¾‹ skill å†…å®¹"""
        if skill_id not in self.metadata:
            return ""
        
        meta = self.metadata[skill_id]
        
        return f"""
# {meta.name}

## æè¿°
{meta.description}

## æ ‡ç­¾
{', '.join(meta.tags)}

## å‰ç½®è¦æ±‚
{', '.join(meta.prerequisites) if meta.prerequisites else 'æ— '}

## æ ¸å¿ƒå†…å®¹

è¿™æ˜¯ {meta.name} skill çš„å®Œæ•´å†…å®¹ã€‚

å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥æ˜¯ï¼š
- è¯¦ç»†çš„æ•™ç¨‹å’Œè§£é‡Š
- ä»£ç ç¤ºä¾‹
- æœ€ä½³å®è·µ
- å¸¸è§é™·é˜±å’Œè§£å†³æ–¹æ¡ˆ
- å‚è€ƒèµ„æ–™

## ç›¸å…³ Skills
{', '.join(meta.related)}

---

æœ¬ skill åŒ…å«çº¦ {meta.estimated_tokens} ä¸ª tokensã€‚
"""


# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»£ç†ç³»ç»Ÿé›†æˆç¤ºä¾‹
# ============================================================================

class IntelligentAgent:
    """ä½¿ç”¨æ¸è¿›å¼åŠ è½½çš„æ™ºèƒ½ä»£ç†"""
    
    def __init__(self, name: str, skills_dir: str):
        self.name = name
        self.skill_loader = ProgressiveSkillLoader(skills_dir)
        self.context_budget = 8000  # tokens
        self.active_skills = []
    
    def start(self):
        """å¯åŠ¨ä»£ç†"""
        print(f"ğŸ¤– ä»£ç† '{self.name}' å¯åŠ¨ä¸­...\n")
        
        # åˆå§‹åŒ–ï¼ˆåŠ è½½å…ƒæ•°æ®ï¼‰
        stats = self.skill_loader.initialize()
        
        print(f"ğŸ“Š åˆå§‹çŠ¶æ€:")
        print(f"   - å¯ç”¨ skills: {stats['total_skills']}")
        print(f"   - å…ƒæ•°æ®å¤§å°: {stats['total_metadata_size_kb']:.1f} KB")
        print(f"   - åˆå§‹åŒ–ç”¨æ—¶: {stats['init_time_ms']:.1f} ms\n")
    
    def handle_query(self, query: str):
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        print(f"ğŸ‘¤ ç”¨æˆ·: {query}\n")
        
        # ç¬¬1æ­¥ï¼šæœç´¢ç›¸å…³ skillsï¼ˆæå¿«ï¼‰
        relevant = self.skill_loader.search_skills(query)
        
        if not relevant:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ skills\n")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(relevant)} ä¸ªç›¸å…³ skills:\n")
        
        # ç¬¬2æ­¥ï¼šæ£€æŸ¥ token é¢„ç®—
        total_tokens = sum(s['tokens'] for s in relevant.values())
        
        if total_tokens > self.context_budget:
            print(f"âš ï¸  æ€»å¤§å° {total_tokens} tokensï¼Œè¶…è¿‡é¢„ç®— {self.context_budget}")
            print(f"   åªåŠ è½½æœ€ç›¸å…³çš„éƒ¨åˆ†\n")
            
            # é€‰æ‹©æœ€ç›¸å…³çš„ skills
            selected = sorted(
                relevant.items(),
                key=lambda x: x[1]['tokens']
            )[:self.context_budget // 1000]
            relevant = dict(selected)
        
        # ç¬¬3æ­¥ï¼šæŒ‰éœ€åŠ è½½ skills
        print(f"ğŸ“¥ æŒ‰éœ€åŠ è½½ skills:\n")
        
        for skill_id, info in relevant.items():
            print(f"   â€¢ {info['name']} (~{info['tokens']} tokens)")
            content = self.skill_loader.load_full_skill(skill_id)
            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæŠŠ content åŠ å…¥ LLM æç¤º
        
        print()
        
        # ç¬¬4æ­¥ï¼šæ˜¾ç¤ºç»Ÿè®¡
        stats = self.skill_loader.get_load_statistics()
        print(f"ğŸ“Š åŠ è½½ç»Ÿè®¡:")
        print(f"   - å·²åŠ è½½ skills: {stats['loaded_skills']}/{stats['total_skills']}")
        print(f"   - ç¼“å­˜å¤§å°: {stats['cache_size_bytes'] / 1024:.1f} KB")
        print(f"   - è®¿é—®æ¬¡æ•°: {stats['access_count']}")
        print(f"   - æ€»åŠ è½½æ—¶é—´: {stats['total_load_time_ms']:.1f} ms\n")


# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šæ¼”ç¤º
# ============================================================================

def main():
    print("=" * 70)
    print("æ¸è¿›å¼æŠ«éœ²ï¼ˆProgressive Disclosureï¼‰æ¼”ç¤º")
    print("=" * 70)
    print()
    
    # åˆ›å»ºä»£ç†
    agent = IntelligentAgent("ResearchAssistant", "./skills")
    
    # å¯åŠ¨ä»£ç†
    agent.start()
    
    # æ¨¡æ‹Ÿç”¨æˆ·æŸ¥è¯¢
    queries = [
        "å¤šä»£ç†",          # ä¼šåŒ¹é… "multi-agent-patterns"
        "ä¸Šä¸‹æ–‡",          # ä¼šåŒ¹é… context-* ç›¸å…³ skills
        "å·¥å…·è®¾è®¡",        # ä¼šåŒ¹é… "tool-design"
    ]
    
    for query in queries:
        agent.handle_query(query)
        print("-" * 70)
        print()


if __name__ == "__main__":
    main()
    
    print("\nâœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("\nå…³é”®è¦ç‚¹:")
    print("1. å¯åŠ¨æ—¶åªåŠ è½½å…ƒæ•°æ®ï¼ˆ< 100msï¼‰")
    print("2. æœç´¢åŸºäºå…ƒæ•°æ®ï¼Œæå¿«ï¼ˆ< 10msï¼‰")
    print("3. æŒ‰éœ€åŠ è½½å®Œæ•´å†…å®¹ï¼ˆ~ 100msï¼‰")
    print("4. ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼ˆ< 1msï¼‰")
    print("\næ€§èƒ½æå‡ï¼š10-20 å€ï¼ ğŸš€")

