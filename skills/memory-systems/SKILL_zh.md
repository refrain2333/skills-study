---
name: memory-systems
description: 为智能体系统设计和实现记忆架构。当构建需要跨会话持久化状态、维护实体一致性或基于结构化知识进行推理的智能体时使用。
---

# 记忆系统设计

记忆提供了持久化层，允许智能体在不同会话之间保持连续性，并对积累的知识进行推理。简单的智能体完全依赖上下文作为记忆，当会话结束时会丢失所有状态。复杂的智能体实现分层记忆架构，在即时上下文需求与长期知识保留之间取得平衡。从向量存储到知识图谱再到时序知识图谱的演进，代表了在结构化记忆方面的投入增加，以实现更好的检索和推理。

## 何时启用

在以下情况下启用此技能：
- 构建必须跨会话持久化的智能体
- 需要在对话中维护实体一致性
- 实现基于积累知识的推理
- 设计能够从过去交互中学习的系统
- 创建随时间增长的知识库
- 构建能够追踪状态变化的时序感知系统

## 核心概念

记忆存在于从即时上下文到永久存储的光谱中。在光谱的一端，上下文窗口中的工作记忆提供零延迟访问，但会在会话结束时消失。在另一端，永久存储无限期持久化，但需要通过检索进入上下文。

简单的向量存储缺乏关系和时间结构。知识图谱保留关系以供推理。时序知识图谱为时间感知查询添加了有效期限。实现选择取决于查询复杂度、基础设施限制和准确性要求。

## 详细主题

### 记忆架构基础

**上下文-记忆光谱**
记忆存在于从即时上下文到永久存储的光谱中。在光谱的一端，上下文窗口中的工作记忆提供零延迟访问，但会在会话结束时消失。在另一端，永久存储无限期持久化，但需要检索才能进入上下文。有效的架构在这一光谱中应用多个层级。

该光谱包括工作记忆（上下文窗口，零延迟，易失）、短期记忆（会话级持久，可搜索，易失）、长期记忆（跨会话持久，结构化，半永久）和永久记忆（归档级，可查询，永久）。每一层具有不同的延迟、容量和持久化特性。

**为什么简单的向量存储不够用**
向量 RAG 通过在共享嵌入空间中嵌入查询和文档来提供语义检索。相似性搜索检索语义最相关的文档。这在文档检索方面表现良好，但对智能体记忆而言缺乏结构。

向量存储会丢失关系信息。如果智能体了解到“客户 X 在 Z 日期购买了产品 Y”，向量存储在被直接问及时可以检索到这一事实。但它无法回答“购买了产品 Y 的客户还购买了哪些产品？”，因为关系结构没有被保留。

向量存储也难以处理时效性。事实会随时间变化，但向量存储除了通过显式元数据和过滤外，没有机制区分“当前事实”和“过时事实”。

**向基于图的记忆演进**
知识图谱保留实体之间的关系。图不是孤立的文档块，而是编码了实体 A 与实体 B 具有关系 R。这使得查询可以遍历关系而不仅仅是相似性。

时序知识图谱为事实添加了有效期限。每个事实都有一个“生效时间”以及（可选的）“失效时间”戳。这使得时间旅行查询能够重建特定时间点的知识。

**基准性能对比**
深度记忆检索 (DMR) 基准提供了跨记忆架构的具体性能数据：

| 记忆系统 | DMR 准确率 | 检索延迟 | 备注 |
|---------------|--------------|-------------------|-------|
| Zep (时序知识图谱) | 94.8% | 2.58s | 准确率最高，检索快 |
| MemGPT | 93.4% | 可变 | 良好的通用性能 |
| GraphRAG | ~75-85% | 可变 | 比基准 RAG 提升 20-35% |
| 向量 RAG | ~60-70% | 快 | 丢失关系结构 |
| 递归摘要 | 35.3% | 低 | 严重的信息丢失 |

Zep 证明了与全上下文基准相比，检索延迟降低了 90%（2.58s vs GPT-5.2 的 28.9s）。这种效率来自于仅检索相关的子图，而不是整个上下文历史。

GraphRAG 在复杂推理任务中比基准 RAG 实现了约 20-35% 的准确率提升，并通过基于社区的摘要减少了高达 30% 的幻觉。

### 记忆层级架构

**第 1 层：工作记忆**
工作记忆是上下文窗口本身。它提供对当前正在处理的信息的即时访问，但容量有限，且在会话结束时消失。

工作记忆的使用模式包括：智能体跟踪中间结果的草稿本计算、为当前任务保留对话的对话历史、跟踪活动目标进度的当前任务状态，以及保存当前正在使用的信息的主动检索文档。

通过仅保留活动信息、在工作成果脱离注意力前进行摘要，以及将关键信息放置在注意力偏好的位置来优化工作记忆。

**第 2 层：短期记忆**
短期记忆在当前会话中持久化，但不会跨会话。它提供搜索和检索能力，且没有永久存储的延迟。

常见的实现方式包括：持续到会话结束的会话级数据库、指定会话目录中的文件系统存储，以及以会话 ID 为键的内存缓存。

短期记忆的用例包括：跨轮次跟踪对话状态而无需堆塞上下文、存储可能稍后需要的工具调用中间结果、维护任务清单和进度跟踪，以及在会话内缓存检索到的信息。

**第 3 层：长期记忆**
长期记忆无限期地跨会话持久化。它使智能体能够从过去的交互中学习，并随时间构建知识。

长期记忆的实现范围从简单的键值存储到复杂的图数据库。选择取决于要建模的关系复杂度、所需的查询模式以及可接受的基础设施复杂度。

长期记忆的用例包括：跨会话学习用户偏好、构建随时间增长的领域知识库、维护具有关系历史的实体注册表，以及存储可重用的成功模式。

**第 4 层：实体记忆**
实体记忆专门跟踪有关实体（人、地点、概念、对象）的信息以保持一致性。这创建了一个初步的知识图谱，其中实体在多次交互中被识别。

实体记忆通过跟踪一次对话中提到的“张三”与另一次对话中是同一个人来维护实体身份。它通过存储随时间发现的关于实体的事实来维护实体属性。它通过跟踪发现的实体间的关系来维护实体关系。

**第 5 层：时序知识图谱**
时序知识图谱通过明确的有效期限扩展了实体记忆。事实不仅是真或假，而是在特定时间范围内为真。

这使得能够执行类似“用户在 X 日期的地址是什么？”的查询，通过检索在该日期范围内有效的事实。它防止了当过时信息与新数据冲突时产生的上下文冲突。它实现了关于实体随时间变化的逻辑推理。

### 记忆实现模式

**模式 1：文件系统即记忆**
文件系统本身可以作为记忆层。这种模式简单，不需要额外的基础设施，并支持使基于文件系统的上下文生效的即时加载。

实现时使用文件系统层级进行组织。使用传达含义的命名约定。以结构化格式（JSON、YAML）存储事实。在文件名或元数据中使用时间戳进行时序跟踪。

优点：简单、透明、可移植。
缺点：无语义搜索、无关系跟踪、需要手动组织。

**模式 2：带元数据的向量 RAG**
增强了丰富元数据的向量存储提供具有过滤能力的语义搜索。

实现时嵌入事实或文档，并存储包含实体标签、时序有效性、来源归属和置信度分数的元数据。查询时在语义搜索的同时包含元数据过滤器。

**模式 3：知识图谱**
知识图谱显式地建模实体和关系。实现时定义实体类型和关系类型，使用图数据库或属性图存储，并为常用查询模式维护索引。

**模式 4：时序知识图谱**
时序知识图谱为事实添加了有效期限，支持时间旅行查询，并防止过时信息导致的上下文冲突。

### 记忆检索模式

**语义检索**
使用嵌入相似性搜索检索与当前查询语义相似的记忆。

**基于实体的检索**
通过遍历图关系检索与特定实体相关的所有记忆。

**时序检索**
使用有效期限过滤器检索在特定时间或时间范围内有效的记忆。

### 记忆整合

记忆随时间积累，需要整合以防止无限增长并移除过时信息。

**整合触发器**
在记忆大量积累后、检索返回过多过时结果时、按计划定期触发，或在请求显式整合时触发整合。

**整合过程**
识别过时事实、合并相关事实、更新有效期限、归档或删除废弃事实，并重建索引。

## 实践指南

### 与上下文集成

记忆必须与上下文系统集成才能发挥作用。使用即时记忆加载在需要时检索相关记忆。使用策略性注入将记忆放置在注意力偏好的位置。

### 记忆系统选择

根据需求选择记忆架构：
- 简单的持久化需求：文件系统记忆
- 语义搜索需求：带元数据的向量 RAG
- 关系推理需求：知识图谱
- 时序有效性需求：时序知识图谱

## 示例

**示例 1：实体跟踪**
```python
# 跨对话跟踪实体
def remember_entity(entity_id, properties):
    memory.store({
        "type": "entity",
        "id": entity_id,
        "properties": properties,
        "last_updated": now()
    })

def get_entity(entity_id):
    return memory.retrieve_entity(entity_id)
```

**示例 2：时序查询**
```python
# 用户在 2024 年 1 月 15 日的地址是什么？
def query_address_at_time(user_id, query_time):
    return temporal_graph.query("""
        MATCH (user)-[r:LIVES_AT]->(address)
        WHERE user.id = $user_id
        AND r.valid_from <= $query_time
        AND (r.valid_until IS NULL OR r.valid_until > $query_time)
        RETURN address
    """, {"user_id": user_id, "query_time": query_time})
```

## 指南

1. 使记忆架构与查询需求相匹配
2. 为记忆访问实现渐进式披露
3. 使用时序有效性防止过时信息冲突
4. 定期整合记忆以防止无限增长
5. 优雅地设计记忆检索失败的处理机制
6. 考虑持久化记忆的隐私影响
7. 为关键记忆实现备份和恢复
8. 随时间监控记忆增长和性能

## 集成

此技能基于 context-fundamentals（上下文基础）。它连接到：

- multi-agent-patterns - 跨智能体的共享记忆
- context-optimization - 基于记忆的上下文加载
- evaluation - 评估记忆质量

## 参考资料

内部参考：
- [实现参考](./references/implementation_zh.md) - 详细的实现模式

本集合中的相关技能：
- context-fundamentals - 上下文基础
- multi-agent-patterns - 跨智能体记忆

外部资源：
- 图数据库文档 (Neo4j 等)
- 向量存储文档 (Pinecone, Weaviate 等)
- 关于知识图谱和推理的研究

---

## 技能元数据

**创建日期**: 2025-12-20
**上次更新**: 2025-12-20
**作者**: Agent Skills for Context Engineering Contributors
**版本**: 1.0.0

