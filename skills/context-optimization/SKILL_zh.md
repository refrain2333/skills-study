---
name: 上下文优化
description: 应用优化技术扩展有效上下文容量。当上下文限制约束智能体性能、需要优化成本或延迟，或实现长期运行的智能体系统时使用。
---

# 上下文优化技术

上下文优化通过战略性的压缩 (compaction)、掩蔽 (masking)、缓存 (caching) 和分区 (partitioning) 来扩展有限上下文窗口的有效容量。目标不是魔法般地增加上下文窗口，而是更好地利用现有容量。有效的优化可以在不要求更大模型或更长上下文的情况下，将有效上下文容量增加两倍或三倍。

## 何时激活

在以下情况下激活本技能：
- 上下文限制约束了任务复杂度
- 针对成本降低进行优化（更少的令牌 = 更低的成本）
- 减少长对话的延迟
- 实现长期运行的智能体系统
- 需要处理更大的文档或对话
- 大规模构建生产系统

## 核心概念

上下文优化通过四种主要策略扩展有效容量：**压缩 (Compaction)**（在接近限制时总结上下文）、**观察掩蔽 (Observation Masking)**（用引用替换冗长的输出）、**KV 缓存优化 (KV-cache optimization)**（重用缓存的计算结果）以及 **上下文分区 (Context Partitioning)**（将工作拆分到隔离的上下文中）。

关键见解是：**上下文质量比数量更重要**。优化在减少噪声的同时保留了信号。艺术在于选择保留什么、丢弃什么，以及何时应用每种技术。

## 详细主题

### 压缩策略 (Compaction Strategies)

**什么是压缩**
压缩是指在接近限制时总结上下文内容，然后用摘要重新初始化一个新的上下文窗口的做法。这以高保真度提炼了上下文窗口的内容，使智能体能够以最小的性能退化继续工作。

压缩通常是上下文优化的第一杠杆。艺术在于选择保留什么与丢弃什么。

**压缩实现**
压缩的工作原理是：识别可以压缩的部分，生成捕获要点的摘要，并用摘要替换全部内容。压缩的优先级依次为：工具输出（替换为摘要）、旧的回合（总结早期对话）、检索到的文档（如果存在较新版本则总结），**严禁压缩系统提示词**。

**摘要生成**
有效的摘要根据消息类型保留不同的元素：

- **工具输出**：保留关键发现、指标和结论。移除冗长的原始输出。
- **对话回合**：保留关键决策、承诺和上下文转移。移除填充内容和反复交谈。
- **检索到的文档**：保留关键事实和断言。移除支持证据和详细阐述。

### 观察掩蔽 (Observation Masking)

**观察结果问题**
在智能体轨迹中，工具输出可能占据 80% 以上的令牌使用量。其中大部分是已经发挥过作用的冗长输出。一旦智能体利用工具输出做出了决定，保留完整输出的价值就会递减，同时消耗大量上下文。

观察掩蔽用精简的引用替换冗长的工具输出。如果需要，信息仍然可以访问，但不会持续消耗上下文。

**掩蔽策略选择**
并非所有观察结果都应被同等掩蔽：

- **绝不掩蔽**：对当前任务至关重要的观察、最近一个回合的观察、正用于活动推理的观察。
- **考虑掩蔽**：3 回合之前的观察、可以提取要点的冗长输出、其目的已实现的观察。
- **始终掩蔽**：重复的输出、样板式的页眉/页脚、对话中已被总结的输出。

### KV 缓存优化 (KV-Cache Optimization)

**理解 KV 缓存**
KV 缓存存储推理期间计算出的 Key 和 Value 张量，随序列长度线性增长。跨共享相同前缀的请求缓存 KV 缓存可以避免重复计算。

**前缀缓存 (Prefix caching)** 使用基于哈希的块匹配，跨具有相同前缀的请求重用 KV 块。这极大地降低了对于具有共同前缀（如系统提示词）的请求的成本和延迟。

**缓存优化模式**
通过重新排序上下文元素来最大化缓存命中率。将稳定元素放在首位（系统提示词、工具定义），然后是频繁重用的元素，最后是独特的元素。

设计提示词以最大化缓存稳定性：避免像时间戳这样的动态内容，使用一致的格式，保持跨会话的结构稳定。

### 上下文分区策略 (Context Partitioning Strategies)

**子智能体分区**
上下文优化最激进的形式是将工作划分给具有隔离上下文的子智能体。每个子智能体在一个专注于其子任务的干净上下文中运行，而不携带来自其他子任务的累积上下文。

这种方法实现了 **关注点分离 (Separation of Concerns)** —— 详细的搜索上下文在子智能体内部保持隔离，而协调者则专注于综合与分析。

**结果聚合**
通过验证所有分区已完成、合并兼容的结果、如果仍然太大则进行总结，来聚合分区的子任务结果。

### 预算管理

**上下文预算分配**
设计显式的上下文预算。为各个类别分配令牌：系统提示词、工具定义、检索文档、消息历史和预留缓冲区。针对预算监控使用情况，并在接近限制时触发优化。

**基于触发器的优化**
监控优化触发信号：令牌利用率高于 80%、退化指标和性能下降。根据上下文组成应用适当的优化技术。

## 实践指南

### 优化决策框架

**何时优化：**
- 上下文利用率超过 70%
- 随着对话延长，响应质量下降
- 由于长上下文导致成本增加
- 随着对话长度增加，延迟增加

**应用什么：**
- 工具输出主导：观察掩蔽
- 检索文档主导：摘要或分区
- 消息历史主导：带摘要的压缩
- 多个组成部分：结合多种策略

### 性能考虑

压缩应在质量下降不到 5% 的情况下实现 50-70% 的令牌减少。掩蔽应在被掩蔽的观察中实现 60-80% 的减少。缓存优化应在稳定负载下实现 70% 以上的命中率。

根据测量的有效性对优化策略进行监控和迭代。

## 示例

**示例 1：压缩触发器**
```python
if context_tokens / context_limit > 0.8:
    context = compact_context(context)
```

**示例 2：观察掩蔽**
```python
if len(observation) > max_length:
    ref_id = store_observation(observation)
    return f"[观察结果 {ref_id} 已省略。关键信息：{extract_key(observation)}]"
```

**示例 3：缓存友好排序**
```python
# 稳定内容在前
context = [system_prompt, tool_definitions]  # 可缓存
context += [reused_templates]  # 可重用
context += [unique_content]  # 独特内容
```

## 指南

1. 优化前先测量——了解你的现状
2. 如果可能，在掩蔽之前先应用压缩
3. 通过一致的提示词设计缓存稳定性
4. 在上下文变得成问题之前进行分区
5. 随时间监控优化的有效性
6. 在令牌节省与质量保留之间取得平衡
7. 在生产规模下测试优化
8. 为边缘情况实现优雅降级

## 集成

本技能建立在 `context-fundamentals` 和 `context-degradation` 之上。它关联到：

- `multi-agent-patterns` - 分区即隔离
- `evaluation` - 测量优化有效性
- `memory-systems` - 将上下文卸载到内存

## 参考文献

内部参考：
- [优化技术参考](./references/optimization_techniques_zh.md) - 详细的技术参考

本系列中的相关技能：
- `context-fundamentals` - 上下文基础
- `context-degradation` - 理解何时优化
- `evaluation` - 测量优化

外部资源：
- 关于上下文窗口限制的研究
- KV 缓存优化技术
- 生产工程指南

---

## 技能元数据

**创建日期**: 2025-12-20
**最后更新**: 2025-12-20
**作者**: 上下文工程智能体技能贡献者
**版本**: 1.0.0

