---
name: 上下文退化
description: 识别、诊断并缓解智能体系统中的上下文退化模式。当上下文变大、智能体性能意外下降或调试智能体故障时使用。
---

# 上下文退化模式

随着上下文长度的增加，语言模型会表现出可预测的退化模式。理解这些模式对于诊断故障和设计弹性系统至关重要。上下文退化不是一个二元状态，而是一个性能下降的连续过程，表现为几种不同的方式。

## 何时激活

在以下情况下激活本技能：
- 在长对话过程中，智能体性能意外下降
- 调试智能体产生错误或无关输出的情况
- 设计必须可靠处理大上下文的系统
- 为生产系统评估上下文工程选择
- 调查智能体输出中的“迷失在中间 (lost in middle)”现象
- 分析智能体行为中与上下文相关的故障

## 核心概念

上下文退化通过几种不同的模式表现出来。**“迷失在中间”**现象导致上下文中心的信息获得的注意力较少。**上下文中毒 (Context poisoning)** 发生在错误通过重复引用而复合时。**上下文分心 (Context distraction)** 发生在无关信息淹没相关内容时。**上下文混淆 (Context confusion)** 产生于模型无法确定哪个上下文适用时。**上下文冲突 (Context clash)** 发展于累积的信息直接冲突时。

这些模式是可预测的，并可以通过压缩 (compaction)、掩蔽 (masking)、分区 (partitioning) 和隔离 (isolation) 等架构模式来缓解。

## 详细主题

### “迷失在中间”现象

记录最详尽的退化模式是“迷失在中间”效应，即模型表现出 U 形注意力曲线。上下文开头和结尾的信息能够获得可靠的注意力，而埋在中间的信息则会遭受召回准确率大幅下降的影响。

**经验证据**
研究表明，放置在上下文中间的相关信息的召回准确率比放置在开头或结尾的信息低 10-40%。这不是模型的失败，而是注意力机制和训练数据分布的结果。

模型将大量注意力分配给第一个令牌（通常是 BOS 令牌）以稳定内部状态。这创造了一个吸收注意力预算的“注意力槽 (attention sink)”。随着上下文的增长，有限的预算被拉得更薄，中间令牌无法获得足够的注意力权重来进行可靠检索。

**实际意义**
在设计上下文放置时要考虑注意力模式。将关键信息放在上下文的开头或结尾。考虑信息是被直接查询还是需要支持推理——如果是后者，放置位置的重要性较低，但整体信号质量更为重要。

对于长文档或对话，使用摘要结构，将关键信息呈现在注意力青睐的位置。使用明确的章节标题和过渡来帮助模型导航结构。

### 上下文中毒

上下文中毒发生在幻觉、错误或不正确的信息进入上下文，并通过重复引用而复合时。一旦被中毒，上下文就会创造出强化错误信念的反馈循环。

**中毒是如何发生的**
中毒通常通过三种路径进入。首先，工具输出可能包含错误或模型作为事实接受的意外格式。其次，检索到的文档可能包含模型纳入推理的不正确或过时的信息。第三，模型生成的摘要或中间输出可能引入持久存在于上下文中的幻觉。

复合效应是严重的。如果智能体的目标部分被中毒，它就会制定出需要大量努力才能撤销的策略。后续的每个决策都会引用被中毒的内容，从而强化错误的假设。

**检测与恢复**
观察症状，包括：在之前成功的任务上输出质量下降、工具失调（智能体调用错误的工具或参数）以及尽管尝试纠正但仍持久存在的幻觉。当这些症状出现时，请考虑上下文中毒。

恢复需要移除或替换中毒内容。这可能涉及：将上下文截断到中毒点之前、在上下文中明确指出中毒并要求重新评估，或者从干净的上下文重新开始并仅保留经过验证的信息。

### 上下文分心

上下文分心出现在上下文增长到如此之大，以至于模型过度关注提供的信息而牺牲了其训练知识。模型会关注上下文中的所有内容而不顾其相关性，这创造了使用提供的信息的压力，即使内部知识更准确。

**干扰因素效应**
研究表明，上下文中即使只有一个无关文档也会降低在涉及相关文档的任务上的表现。多个干扰因素会复合退化。这种效应不在于绝对意义上的噪声，而在于注意力分配——无关信息与相关信息竞争有限的注意力预算。

模型没有“跳过”无关上下文的机制。它们必须关注提供的所有内容，这种义务创造了分心，即使无关信息显然没用。

**缓解策略**
通过仔细筛选进入上下文的内容来缓解分心。在加载检索到的文档之前应用相关性过滤。使用命名空间和组织结构，使无关章节在结构上易于忽略。考虑信息是否真正需要存在于上下文中，或者是否可以通过工具调用来访问。

### 上下文混淆

上下文混淆产生于无关信息以降低质量的方式影响响应。这与分心相关但有所不同——混淆关注的是上下文对模型行为的影响，而不仅仅是注意力分配。

如果你把某些内容放进上下文中，模型就必须关注它。模型可能会纳入无关信息、使用不恰当的工具定义或应用来自不同上下文的约束。当上下文包含多种任务类型或在单个会话中切换任务时，混淆尤为严重。

**混淆迹象**
观察以下迹象：响应针对查询的错误方面、工具调用似乎适用于不同的任务、或者输出混合了来自多个来源的要求。这些迹象表明模型对于哪个上下文适用于当前情况感到混淆。

**架构解决方案**
架构解决方案包括：明确的任务细分（不同的任务获得不同的上下文窗口）、任务上下文之间的清晰过渡，以及隔离不同目标的上下文的状态管理。

### 上下文冲突

上下文冲突发展于累积的信息直接冲突，创造出使推理脱轨的矛盾指导。这与中毒不同（中毒是一个信息不正确），在冲突中，多个正确的信息片段相互矛盾。

**冲突来源**
冲突通常源于多源检索（不同来源有矛盾信息）、版本冲突（过时和当前信息同时出现在上下文中）以及观点冲突（不同观点都有效但不兼容）。

**解决方法**
解决方法包括：显式的冲突标记（识别矛盾并请求澄清）、建立哪个来源优先的优先级规则，以及排除上下文中过时信息的版本过滤。

### 经验基准与阈值

研究提供了关于退化模式的具体数据，为设计决策提供参考。

**RULER 基准测试发现**
RULER 基准测试给出了令人清醒的发现：只有 50% 声称具有 32K+ 上下文的模型在 32K 令牌时能维持令人满意的性能。GPT-5.2 在当前模型中显示出最小的退化，而许多模型在扩展上下文中仍下降了 30+ 分。简单的大海捞针 (needle-in-haystack) 测试中的近乎完美得分并不能转化为真实的常上下文理解。

**模型特定的退化阈值**

| 模型 | 退化开始 | 严重退化 | 备注 |
|-------|-------------------|-------------------|-------|
| GPT-5.2 | ~64K 令牌 | ~200K 令牌 | 具有思考模式的最佳综合抗退化性 |
| Claude Opus 4.5 | ~100K 令牌 | ~180K 令牌 | 200K 上下文窗口，极强的注意力管理 |
| Claude Sonnet 4.5 | ~80K 令牌 | ~150K 令牌 | 针对智能体和编码任务进行了优化 |
| Gemini 3 Pro | ~500K 令牌 | ~800K 令牌 | 1M 上下文窗口，原生多模态 |
| Gemini 3 Flash | ~300K 令牌 | ~600K 令牌 | 比 Gemini 2.5 快 3 倍，81.2% MMMU-Pro |

**模型特定的行为模式**
不同的模型在上下文压力下表现出不同的失效模式：

- **Claude 4.5 系列**：具有校准不确定性的最低幻觉率。Claude Opus 4.5 在 SWE-bench Verified 上达到 80.9%。倾向于拒绝或请求澄清，而不是凭空捏造。
- **GPT-5.2**：提供两种模式——即时（快）和思考（推理）。思考模式通过逐步验证减少幻觉，但增加了延迟。
- **Gemini 3 Pro/Flash**：具有 1M 上下文窗口的原生多模态。Gemini 3 Flash 相比前代提供 3 倍速度提升。擅长跨文本、代码、图像、音频和视频的多模态推理。

这些模式为不同用例的模型选择提供了参考。高风险任务受益于 Claude 4.5 的保守方法或 GPT-5.2 的思考模式；对速度敏感的任务可以使用即时模式。

### 违背直觉的发现

研究揭示了几种违背直觉的模式，挑战了关于上下文管理的假设。

**乱序的干草堆优于连贯的干草堆**
研究发现，乱序（不连贯）的干草堆比逻辑连贯的干草堆产生更好的性能。这表明连贯的上下文可能会创造出迷惑检索的虚假关联，而不连贯的上下文则迫使模型依赖精确匹配。

**单个干扰因素具有超常影响**
即使是一个无关文档也会显著降低性能。这种效应与噪声量不成正比，而是遵循一个阶梯函数，即任何干扰因素的出现都会触发退化。

**针-题相似度相关性**
针（目标信息）与问题对之间的相似度越低，随上下文长度增加的退化越快。需要在互不相似的内容之间进行推理的任务尤为脆弱。

### 什么时候大上下文会起反作用

更大的上下文窗口并不能一致地提高性能。在许多情况下，更大的上下文创造出的新问题超过了其收益。

**性能退化曲线**
模型随上下文长度表现出非线性退化。性能在达到阈值之前保持稳定，然后迅速退化。阈值随模型和任务复杂度而异。对于许多模型，即使上下文窗口支持更大的尺寸，有意义的退化从 8,000-16,000 令牌就开始了。

**成本影响**
处理成本随上下文长度不成比例地增长。处理 400K 令牌上下文的成本不是 200K 的两倍——它在时间和计算资源上都呈指数级增长。对于许多应用来说，这使得大上下文处理在经济上是不切实际的。

**认知负荷比喻**
即使拥有无限的上下文，要求单个模型在几十个独立的任务中保持一致的质量也会创造认知瓶颈。模型必须不断在项目之间切换上下文，保持比较框架，并确保风格一致。这不是更多上下文能解决的问题。

## 实践指南

### 四桶方法 (The Four-Bucket Approach)

四种策略针对上下文退化的不同方面：

**写 (Write)**：使用暂存器 (scratchpad)、文件系统或外部存储将上下文保存到窗口之外。这使活动上下文保持精简，同时保留信息访问。

**选 (Select)**：通过检索、过滤和优先级排序将相关上下文拉入窗口。这通过排除无关信息来解决分心问题。

**压 (Compress)**：通过摘要、抽象和观察掩蔽在保留信息的同时减少令牌。这扩展了有效上下文容量。

**隔 (Isolate)**：将上下文拆分到子智能体或会话中，防止任何单一上下文增长到足以退化的程度。这是最激进的策略，但通常也是最有效的。

### 架构模式

通过特定的架构模式实现这些策略。使用 **即时上下文加载 (just-in-time context loading)** 仅在需要时检索信息。使用 **观察掩蔽 (observation masking)** 用精简引用替换冗长的工具输出。使用 **子智能体架构 (sub-agent architectures)** 隔离不同任务的上下文。使用 **压缩 (compaction)** 在上下文超过限制之前对其进行总结。

## 示例

**示例 1：检测退化**
```yaml
# 长对话期间上下文增长
turn_1: 1000 tokens
turn_5: 8000 tokens
turn_10: 25000 tokens
turn_20: 60000 tokens (退化开始)
turn_30: 90000 tokens (显著退化)
```

**示例 2：缓解“迷失在中间”**
```markdown
# 将关键信息放在边缘组织上下文

[当前任务]                      # 开头 (Attention favored)
- 目标：生成季度报告
- 截止日期：本周末

[详细上下文]                  # 中间 (Attention degraded)
- 50 页数据
- 多个分析章节
- 支持证据

[关键发现]                     # 结尾 (Attention favored)
- 收入增长 15%
- 成本下降 8%
- A 地区增长
```

## 指南

1. 在开发过程中监控上下文长度与性能的相关性
2. 将关键信息放在上下文的开头或结尾
3. 在退化变得严重之前实现压缩触发器
4. 在将检索到的文档添加到上下文之前验证其准确性
5. 使用版本控制防止过时信息导致冲突
6. 细分任务以防止不同目标之间的上下文混淆
7. 针对“优雅降级”进行设计，而不是假设完美条件
8. 使用逐渐增大的上下文进行测试以找到退化阈值

## 集成

本技能建立在 `context-fundamentals` 之上，应在理解基本上下文概念之后学习。它关联到：

- `context-optimization` - 缓解退化的技术
- `multi-agent-patterns` - 使用隔离来防止退化
- `evaluation` - 在生产中测量和检测退化

## 参考文献

内部参考：
- [退化模式参考](./references/patterns_zh.md) - 详细的技术参考

本系列中的相关技能：
- `context-fundamentals` - 上下文基础
- `context-optimization` - 缓解技术
- `evaluation` - 检测与测量

外部资源：
- 关于注意力机制和上下文窗口限制的研究
- 关于“迷失在中间”现象的研究
- 来自 AI 实验室的生产工程指南

---

## 技能元数据

**创建日期**: 2025-12-20
**最后更新**: 2025-12-20
**作者**: 上下文工程智能体技能贡献者
**版本**: 1.0.0

