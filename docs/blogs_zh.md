---
name: context-engineering-blogs-zh
description: 关于上下文工程的技术博客集合，涵盖代理系统中上下文窗口管理策略，包括写入、选择、压缩和隔离模式。
doc_type: blog
source_url: 原文来自Anthropic博客
---

# 上下文工程博客中文翻译

最近阅读的一些有价值的技术博客：

---

## 第一篇：上下文工程 (Context Engineering)

**阅读时间：** 11分钟  
**发布日期：** 2025年7月2日

### 摘要（TL;DR）

代理需要上下文来执行任务。上下文工程是在代理轨迹的每一步中使用恰当信息填充上下文窗口的艺术与科学。本文分解了一些常见策略——写入、选择、压缩和隔离——通过审视各种流行的代理和论文来讲解上下文工程。然后解释LangGraph是如何被设计来支持这些策略的！

---

### 上下文工程的一般分类

正如Andrej Karpathy所说，大语言模型就像是一种新型的操作系统。LLM就像CPU，其上下文窗口就像RAM，充当模型的工作内存。正如RAM一样，LLM上下文窗口的容量有限，需要处理各种来源的上下文。就像操作系统精选什么内容适合放入CPU的RAM一样，我们可以思考"上下文工程"的作用。Karpathy很好地总结了这一点：

> 上下文工程是"为代理的下一步用恰好合适的信息填充上下文窗口的微妙的艺术与科学"

---

### LLM应用中常见的上下文类型

在构建LLM应用时，我们需要管理哪些类型的上下文？上下文工程涵盖了几种不同的上下文类型：

- **指令** —— 提示词、记忆、少样本示例、工具描述等
- **知识** —— 事实、记忆等
- **工具** —— 工具调用的反馈

---

### 代理的上下文工程

今年，随着LLM在推理和工具调用方面的改进，人们对代理的兴趣大幅增长。代理会交错进行LLM调用和工具调用，通常用于长时间运行的任务。代理会交错进行LLM调用和工具调用，利用工具反馈来决定下一步的操作。

然而，长时间运行的任务和来自工具调用的累积反馈意味着代理通常会使用大量的令牌。这会导致许多问题：可能超过上下文窗口的大小、增加成本/延迟，或降低代理的性能。Drew Breunig很好地列举了更长的上下文导致性能问题的具体方式，包括：

- **上下文中毒（Context Poisoning）**：当一个幻觉进入上下文中
- **上下文分心（Context Distraction）**：当上下文淹没了训练
- **上下文困惑（Context Confusion）**：当多余的上下文影响了响应
- **上下文冲突（Context Clash）**：当上下文的各部分不一致

来自工具调用的上下文在多个代理回合中累积。

鉴于此，Cognition指出了上下文工程的重要性：

> "上下文工程"…实际上是构建AI代理的工程师的**第一要务**

Anthropic也清楚地阐述了这一点：

> 代理经常参与跨越数百轮的对话，需要仔细的上下文管理策略。

那么，人们今天如何应对这一挑战呢？我们将代理上下文工程的常见策略分为四个主要类别——写入、选择、压缩和隔离——并从流行代理产品和论文中给出了每种策略的示例。然后解释LangGraph是如何被设计来支持这些策略的！

---

### 上下文工程的一般分类

#### 1. 写入上下文（Write Context）

写入上下文意味着将其保存在上下文窗口外，以帮助代理执行任务。

**草稿簿（Scratchpads）**

当人类解决任务时，我们会记笔记，为将来的相关任务记住事情。代理也在获得这些能力！通过"草稿簿"进行笔记是在代理执行任务时保留信息的一种方法。想法是将信息保存在上下文窗口之外，以便代理可以使用它。Anthropic的多代理研究员提供了一个清晰的例子：

> LeadResearcher首先思考方法并将其计划保存到Memory中以保留上下文，因为如果上下文窗口超过200,000个令牌，它将被截断，重要的是保留计划。

草稿簿可以用几种不同的方式实现。它们可以是简单写入文件的工具调用。它们也可以是在运行时状态对象中的一个字段，在会话期间保存。无论哪种情况，草稿簿都让代理能够保存有用的信息来帮助他们完成任务。

**记忆（Memories）**

草稿簿帮助代理在给定的会话（或线程）内解决任务，但有时代理受益于跨许多会话记住事情！Reflexion引入了在每个代理回合后进行反思和重新使用这些自生成的记忆的想法。生成代理（Generative Agents）创建了从过去代理反馈集合中定期合成的记忆。

LLM可用于更新或创建记忆。

这些概念已经进入ChatGPT、Cursor和Windsurf等流行产品，所有这些产品都具有基于用户-代理交互自动生成可跨会话持久存在的长期记忆的机制。

---

### 2. 选择上下文（Select Context）

选择上下文意味着将其拉入上下文窗口以帮助代理执行任务。

**从草稿簿中选择**

从草稿簿选择上下文的机制取决于如何实现草稿簿。如果它是一个工具，那么代理可以通过进行工具调用来简单地读取它。如果它是代理运行时状态的一部分，那么开发人员可以选择在每一步向代理公开状态的哪些部分。这为暴露草稿簿上下文到后续回合提供了细粒度的控制。

**选择记忆**

如果代理能够保存记忆，他们也需要能够选择与他们正在执行的任务相关的记忆。这可能出于几个原因很有用。代理可能会选择少样本示例（情节记忆）作为所需行为的示例、指令（程序性记忆）来指导行为、或事实（语义记忆）来获取与任务相关的上下文。

一个挑战是确保选择相关的记忆。一些流行的代理简单地使用一个始终被拉入上下文的文件集。例如，许多代码代理使用特定的文件来保存指令（"程序性"记忆）或者在某些情况下保存示例（"情节"记忆）。Claude Code使用CLAUDE.md。Cursor和Windsurf使用规则文件。

但是，如果代理存储了更大的事实和/或关系集合（例如语义记忆），选择就变得更难了。ChatGPT是一个很好的例子，说明了一个存储和从大量用户特定记忆中选择的流行产品。

嵌入和/或知识图通常用于协助选择。不过，记忆选择仍然充满挑战。在AIEngineer World's Fair上，Simon Willison分享了一个选择出错的例子：ChatGPT从记忆中获取了他的位置，并在请求的图像中意外地注入了它。这种意外或不需要的记忆检索会让一些用户感到上下文窗口"不再属于他们"！

**工具**

代理使用工具，但如果提供太多工具可能会变得超载。这通常是因为工具描述重叠，导致模型对使用哪个工具感到困惑。一种方法是对工具描述应用RAG（检索增强生成）以仅获取与任务最相关的工具。最近的一些论文表明这将工具选择准确度提高了3倍。

**知识**

RAG是一个丰富的主题，可能是一个中心的上下文工程挑战。代码代理是大规模生产中RAG的一些最好的例子。来自Windsurf的Varun很好地捕捉了其中的一些挑战：

> 索引代码≠上下文检索…[我们正在进行索引和嵌入搜索…[与]AST解析代码并沿语义有意义的边界进行分块…当代码库大小增长时，嵌入搜索作为检索启发式变得不可靠…我们必须依赖grep/文件搜索、基于知识图的检索和…一个重新排名步骤，其中[上下文]按相关性顺序排列。

---

### 3. 压缩上下文（Compressing Context）

压缩上下文涉及仅保留执行任务所需的令牌。

**上下文总结**

代理交互可以跨越数百个回合并使用令牌繁重的工具调用。总结是管理这些挑战的一种常见方式。如果你使用过Claude Code，你已经看到这个过程中的行动。Claude Code在超过95%的上下文窗口后运行"自动压缩"，它将总结用户-代理交互的完整轨迹。这种跨代理轨迹的压缩可以使用各种策略，如递归或分层总结。

可以应用总结的几个位置。

在代理设计的特定点应用总结也很有用。例如，它可以用于后处理某些工具调用（例如，令牌繁重的搜索工具）。作为第二个例子，Cognition提到在代理边界处进行总结以减少知识交接期间的令牌。总结如果需要捕捉特定的事件或决定可能会很有挑战性。Cognition为此使用了微调模型，这强调了这一步可能需要付出多少工作。

**上下文修剪**

而总结通常使用LLM来提炼最相关的上下文片段，修剪可以经常过滤或如Drew Breunig所指出的"修剪"上下文。这可以使用硬编码的启发式方法，如从列表中删除较早的消息。Drew也提到了Provence，一个针对问答的训练上下文修剪器。

---

### 4. 隔离上下文（Isolating Context）

隔离上下文涉及将其分割以帮助代理执行任务。

**多代理**

隔离上下文的最流行的方法之一是将其跨子代理分割。OpenAI Swarm库的动力是关注点分离，其中一个代理团队可以处理特定的子任务。每个代理都有一个特定的工具集、指令和自己的上下文窗口。

跨多个代理分割上下文。

Anthropic的多代理研究员为这一点提供了一个案例：许多具有隔离上下文的代理表现优于单代理，主要是因为每个子代理上下文窗口可以分配给更狭隘的子任务。如博客所说：

> [子代理操作]并行地使用自己的上下文窗口，同时探索问题的不同方面。

当然，多代理的挑战包括令牌使用（例如，Anthropic报告的聊天令牌多达15倍），需要仔细的提示工程来规划子代理工作，以及子代理的协调。

**带环境的上下文隔离**

HuggingFace的deep researcher展示了另一个有趣的上下文隔离示例。大多数代理使用工具调用API，它返回可以传递给工具的JSON对象（工具参数）（例如搜索API）来获取工具反馈（例如搜索结果）。HuggingFace使用CodeAgent，其输出包含所需的工具调用。然后代码在沙箱中运行。然后将来自工具调用的选定上下文（例如返回值）传递回LLM。

沙箱可以从LLM隔离上下文。

这允许上下文与LLM隔离在环境中。HuggingFace指出这是隔离令牌繁重对象的好方法：

> [代码代理允许]更好的状态处理…需要存储此图像/音频/其他以供以后使用？没问题，只需在状态中将其分配为变量，然后[稍后使用它]。

**状态**

值得指出的是，代理的运行时状态对象也可以是隔离上下文的好方法。这可以服务与沙箱相同的目的。状态对象可以使用具有上下文可以写入的字段的模式来设计。状态的一个字段（例如消息）可以在代理的每一步暴露给LLM，但模式可以隔离其他字段中的信息以供更选择性的使用。

---

### 使用LangSmith / LangGraph进行上下文工程

那么，你如何应用这些想法呢？开始之前，有两个有帮助的基础部分。首先，确保你有办法查看你的数据并在你的代理中追踪令牌使用。这有助于告知在哪里最好应用上下文工程的工作。LangSmith非常适合代理追踪/可观察性，并提供了一个很好的方式来做到这一点。其次，确保你有一个简单的方法来测试上下文工程是否伤害或改进代理性能。LangSmith支持代理评估来测试任何上下文工程工作的影响。

**写入上下文**

LangGraph被设计用于线程范围（短期）和长期记忆。短期记忆使用检查点来在代理的所有步骤中保留代理状态。这非常有用作为"草稿簿"，允许你写入信息到状态并在代理轨迹的任何步骤中获取它。

LangGraph的长期记忆使你能够在许多会话中与代理保留上下文。它是灵活的，允许你保存小型文件集（例如用户配置文件或规则）或更大的记忆集合。此外，LangMem提供了一套广泛的有用的抽象来协助LangGraph记忆管理。

**选择上下文**

在LangGraph代理的每个节点（步骤）内，你可以获取状态。这给你在每个代理步骤向LLM呈现什么上下文的细粒度控制。

此外，LangGraph的长期记忆在每个节点内是可访问的，支持各种类型的检索（例如获取文件以及在记忆集合上的基于嵌入的检索）。有关长期记忆的概述，请参阅我们的Deeplearning.ai课程。对于应用于特定代理的入门点，请参阅我们的Ambient Agents课程。这展示了如何在可以管理你的电子邮件并从你的反馈中学习的长时间运行的代理中使用LangGraph记忆。

带用户反馈和长期记忆的电子邮件代理。

对于工具选择，LangGraph Bigtool库是对工具描述应用语义搜索的好方法。这有助于在使用大量工具时为任务选择最相关的工具。最后，我们有几个展示如何将各种类型的RAG与LangGraph一起使用的教程和视频。

**压缩上下文**

因为LangGraph是一个低级别的编排框架，你将代理布局为一组节点，定义每个节点中的逻辑，以及定义在它们之间传递的状态对象。这种控制提供了几种压缩上下文的方式。

一种常见的方法是使用消息列表作为你的代理状态，并使用一些内置实用程序定期总结或修剪它。但是，你也可以添加逻辑来后处理工具调用或代理工作阶段的几种不同方式。你可以在特定点添加总结节点，或者也可以向工具调用节点添加总结逻辑以压缩特定工具调用的输出。

**隔离上下文**

LangGraph是围绕状态对象设计的，允许你指定状态模式并在每个代理步骤访问状态。例如，你可以将来自工具调用的上下文存储在状态的某些字段中，将其隔离与LLM分开，直到需要该上下文。除了状态之外，LangGraph支持使用沙箱进行上下文隔离。查看这个仓库以获取使用E2B沙箱的LangGraph代理示例。查看此视频以获取使用Pyodide进行沙箱的示例，其中状态可以被保留。LangGraph还对构建多代理架构提供了大量支持，如监督者和群体库。你可以查看这些视频以获取更多关于将多代理与LangGraph一起使用的详情。

---

### 结论

上下文工程正在成为代理构建者应该致力于掌握的工艺。在这里，我们介绍了在当今许多流行代理中看到的几种常见模式：

- **写入上下文** - 将其保存在上下文窗口外以帮助代理执行任务。
- **选择上下文** - 将其拉入上下文窗口以帮助代理执行任务。
- **压缩上下文** - 仅保留执行任务所需的令牌。
- **隔离上下文** - 将其分割以帮助代理执行任务。

LangGraph使得实现其中每一个变得容易，LangGraph提供了一个简单的方式来测试你的代理并追踪上下文使用。一起，LangGraph和LangGraph启用了一个有益的反馈循环，用于识别应用上下文工程的最佳机会、实施它、测试它，以及重复。

---

**翻译进度：** 第1篇完成 ✓

---

## 第二篇：Manus中的上下文工程

**发布日期：** 2025年10月15日  
**作者：** Lance Martin

### 为什么需要上下文工程

本周早些时候，我与Manus联合创始人兼首席科学官Yichao"Peak"Ji进行了一次网络研讨会。你可以在这里看到视频、我的幻灯片和Peak的幻灯片。以下是我的笔记。

Anthropic将代理定义为LLM指导自己的流程和工具使用的系统，保持对如何完成任务的控制。简而言之，就是LLM在循环中调用工具。

Manus是最受欢迎的通用消费代理之一。典型的Manus任务使用50个工具调用。如果没有上下文工程，这些工具调用结果将在LLM上下文窗口中累积。随着上下文窗口填满，许多人观察到LLM性能下降。

例如，Chroma进行了一项很好的关于上下文衰退的研究，Anthropic解释了如何增长的上下文耗尽了LLM的注意力预算。因此，在构建代理时仔细管理进入LLM上下文窗口的内容很重要。Karpathy清楚地阐述了这一点：

> 上下文工程是为代理轨迹中的下一步用恰好合适的信息填充上下文窗口的微妙的艺术与科学

### 上下文工程方法

每个Manus会话都使用一个专门的基于云的虚拟机，为代理提供一个具有文件系统、导航工具和在该沙箱环境中执行命令（例如提供的实用程序和标准shell命令）的能力的虚拟计算机。

在这个沙箱中，Manus使用三种主要的上下文工程策略，这些策略与Anthropic在这里介绍的方法以及我在许多项目中看到的方法相一致：

1. **减少上下文**
2. **卸载上下文**
3. **隔离上下文**

### 上下文减少

Manus中的工具调用具有"完整"和"紧凑"表示。完整版本包含工具调用的原始内容（例如完整的搜索工具结果），它存储在沙箱中（例如文件系统）。紧凑版本存储对完整结果的引用（例如文件路径）。

Manus将压缩应用于较旧的（"过时的"）工具结果。这只是意味着用紧凑版本替换完整工具结果。这允许代理在需要时仍然获取完整结果，但通过删除代理已经使用过的"过时"结果来节省令牌。

较新的工具结果保持完整以指导代理的下一个决定。这似乎是上下文减少的一个一般有用的策略，我注意到这类似于Anthropic的上下文编辑功能：

> 上下文编辑在接近令牌限制时自动从上下文窗口中清除过时的工具调用和结果。随着你的代理执行任务并累积工具结果，上下文编辑删除过时的内容，同时保留对话流，有效地延长代理在没有手动干预的情况下可以运行的时间。

当压缩达到收益递减（见下图）时，Manus对轨迹应用总结。摘要使用完整工具结果生成，Manus使用模式来定义摘要字段。这为任何代理轨迹创建了一个一致的摘要对象。

### 上下文隔离

Manus对多代理采取了实用的方法，避免拟人化的劳动分工。虽然人类由于认知限制而按角色组织（设计师、工程师、项目经理），但LLM不一定具有这些相同的约束。

考虑到这一点，Manus中子代理的主要目标是隔离上下文。例如，如果有任务要做，Manus会将该任务分配给具有自己上下文窗口的子代理。

Manus使用多代理，其中一个规划者分配任务，一个知识管理者审查对话并确定什么应该保存在文件系统中，以及一个执行子代理来执行规划者分配的任务。

Manus最初使用todo.md进行任务规划，但发现大约三分之一的所有行动都花在更新待办事项列表上，浪费了宝贵的令牌。他们转向了一个专门的规划者代理，调用执行子代理来执行任务。

在最近的播客中，Anthropic的多代理研究Erik Schluntz提到他们类似地设计多代理系统，其中一个规划者分配任务，并使用函数调用作为通信协议来启动子代理。Erik以及Cognition的Walden Yan提出的一个中心挑战是规划者和子代理之间的上下文共享。

Manus用两种方式解决这个问题。对于简单的任务（例如规划者只需要子代理的输出的离散任务），规划者简单地创建指令并通过函数调用将其传递给子代理。这类似于Claude Code的任务工具。

对于更复杂的任务（例如子代理需要写入规划者也使用的文件），规划者与子代理共享其完整上下文。子代理仍然有自己的行动空间（工具）和指令，但接收规划者也有权访问的完整上下文。

在这两种情况下，规划者定义子代理的输出模式。子代理有一个提交结果工具来在返回结果到规划者前填充这个模式，Manus使用约束解码来确保输出符合定义的模式。

### 上下文卸载

**工具定义**

我们通常希望代理能够执行多种操作。当然，我们可以将大量工具绑定到LLM并提供关于如何使用所有工具的详细指令。但是，工具描述使用宝贵的令牌，许多（通常重叠或含糊）工具可能导致模型混淆。

我看到的一个趋势是代理使用一小组通用工具，让代理能够访问计算机。例如，仅使用Bash工具和几个访问文件系统的工具，代理就可以执行广泛的操作！

Manus将这视为具有函数/工具调用和其虚拟计算机沙箱的分层动作空间。Peak提到Manus使用一个小集合（< 20）的原子函数；这包括Bash工具、管理文件系统的工具和代码执行工具之类的东西。

Manus不是膨胀函数调用层，而是将大多数操作卸载到沙箱层。Manus可以使用其Bash工具直接在沙箱中执行许多实用程序，MCP工具通过CLI公开，代理也可以使用Bash工具执行。

Claude的技能功能使用类似的想法：技能存储在文件系统中，而不是作为绑定工具，Claude只需要几个简单的函数调用（Bash、文件系统）来逐步发现和使用它们。

> 渐进式公开是让Agent Skills灵活和可扩展的核心设计原则。就像一份组织良好的手册，从目录开始，然后是特定章节，最后是详细的附录，技能允许Claude仅在需要时加载信息…具有文件系统和代码执行工具的代理在处理特定任务时不需要将整个技能读入他们的上下文窗口。

**工具结果**

因为Manus可以访问文件系统，它也可以卸载上下文（例如工具结果）。如上所述，这是上下文减少的中心；工具结果被卸载到文件系统以生成紧凑版本，这用于从代理的上下文窗口修剪过时的令牌。类似于Claude Code，Manus使用基本实用程序（例如glob和grep）在文件系统中搜索，无需索引（例如vectorstores）。

### 模型选择

Manus不是承诺使用单一模型，而是使用任务级别的路由：它可能对编码使用Claude、对多模态任务使用Gemini，或对数学和推理使用OpenAI。概括地说，Manus对模型选择的方法由成本考虑驱动，KV缓存效率起中心作用。

Manus使用缓存（例如对于系统指令、较旧的工具结果等）来减少代理许多回合中的成本和延迟。Peak提到分布式KV缓存基础设施对于使用开源模型很难实现，但得到了前沿提供者的很好支持。这种缓存支持可以使前沿模型对于某些（代理）用例实际上更便宜。

### 牢记苦涩课程来构建

我们通过讨论苦涩课程来结束了讨论。我一直对其对AI工程的影响感兴趣。Claude Code的创建者Boris Cherny提到"苦涩课程"影响了他的决定，以保持Claude Code不持己见，使其更容易适应模型改进。

在不断改进的模型上构建意味着接受不断的变化。Peak提到自3月推出以来，Manus已经重建了五次！

此外，Peak警告说代理的束缚可能限制性能随着模型的进步；这正是苦涩课程所指出的挑战。我们添加结构以改进给定时间点的性能，但这个结构可能限制性能随着计算（模型）增长。

为了防范这一点，Peak建议在不同的模型强度上运行代理评估。如果性能没有随着更强的模型改进，你的束缚可能在削弱代理。这可以帮助测试你的束缚是否"面向未来"。

OpenAI/MSL的Hyung Won Chung在这个主题上的谈话进一步强调了需要不断重新评估结构（例如你的束缚/假设）随着模型改进。

> 添加给定计算和数据可用级别所需的结构。稍后删除它们，因为这些快捷方式会瓶颈进一步改进。

### 结论

给代理访问计算机（例如文件系统、终端、实用程序）是一个通用的模式，我们在许多代理中看到，包括Manus。它启用了几个上下文工程策略：

**1. 卸载上下文**
- 将工具结果外部存储：将完整工具结果保存到文件系统（不在上下文中）并使用glob和grep等实用程序按需访问
- 将操作推送到沙箱：使用一小组函数调用（Bash、文件系统访问），可以在沙箱中执行许多实用程序，而不是将每个实用程序绑定为工具

**2. 减少上下文**
- 压缩过时结果：随着上下文填满，用引用（例如文件路径）替换较旧的工具结果；保持最近的结果完整以指导下一个决定
- 在必要时总结：一旦压缩达到收益递减，对完整轨迹应用基于模式的总结

**3. 隔离上下文**
- 为离散任务使用子代理：为具有自己上下文窗口的任务分配子代理，主要是为了隔离上下文（不是为了按角色分工）
- 有意共享上下文：对简单任务只传递指令；对需要更多上下文的子代理的复杂任务传递完整上下文（例如轨迹和共享文件系统）

最后考虑的是确保你的束缚不会随着模型改进而限制性能（例如是"苦涩课程-pilled"）。跨模型强度进行测试以验证这一点。简单、不持己见的设计通常更好地适应模型改进。最后，不要害怕随着模型改进而重新构建你的代理（Manus自3月以来重构了5次）！

---

**翻译进度：** 第1、2篇完成 ✓

---

## 第三篇：构建Manus中的AI代理上下文工程

**发布日期：** 2025年7月18日  
**作者：** Yichao 'Peak' Ji

项目初期，我的团队和我面临了一个关键决定：我们应该使用开源基础训练一个端到端的代理模型，还是在前沿模型的能力基础上构建代理？

在我NLP事业的第一个十年，我们没有这个选择的奢侈。在远古时代（是的，已经过了七年），模型在能够转移到新任务之前必须进行微调和评估。这个过程通常每次迭代需要几周，即使模型与今天的LLM相比很小。对于快速发展的应用，特别是前期产品阶段市场契合度（PMF），这样的慢反馈循环是致命的。这是我上一家初创公司的一个苦涩教训，我在那里为语义搜索从头训练模型。然后GPT-3和GPT-4出现了，我的内部模型一夜之间变得不相关。讽刺的是，这些相同的模型标志着上下文学习的开始——以及全新的前进道路。

这个来之不易的教训使选择变得清晰：Manus将投注上下文工程。这使我们能够在数小时而非数周内提供改进，并使我们的产品与基础模型保持正交：如果模型进步是水涨船高，我们希望Manus是船，而不是粘在海底的柱子。

尽管如此，上下文工程证实了任何事物但直截了当。这是一个实验科学——我们已经四次重建我们的代理框架，每次在发现更好的方式后。我们亲切地将这个手动架构搜索、提示调整和经验猜测的过程称为"随机梯度下降"。这不优雅，但它有效。

这篇文章分享了我们通过自己的"SGD"到达的本地最优。如果你正在构建自己的AI代理，我希望这些原则帮助你更快地收敛。

### 围绕KV缓存设计

如果我必须选择只有一个指标，我会争论KV缓存命中率是生产阶段AI代理最关键的单一指标。它直接影响延迟和成本。为了理解为什么，让我们看看大语言模型如何运作：

收到用户输入后，代理进行一系列工具使用来完成任务。在每次迭代中，模型基于当前上下文从预定义的动作空间中选择一个动作。然后该动作在环境中执行（例如Manus的虚拟机沙箱）以产生一个观察。动作和观察被附加到上下文中，形成下一个迭代的输入。这个循环继续直到任务完成。

如你能想象的那样，上下文随着每一步增长，而输出——通常是一个结构化的函数调用——保持相对较短。这使得代理中的前缀填充与解码的比例与聊天机器人相比高度倾斜。例如，在Manus中，平均输入输出令牌比大约是100:1。

幸运的是，具有相同前缀的上下文可以利用前缀缓存，这大幅减少了首令牌时间（TTFT）和推理成本——无论你是使用自托管模型还是调用推理API。我们不是在谈论小的节省：例如，使用Claude Sonnet，缓存的输入令牌成本0.30美元/MTok，而未缓存的成本3美元/MTok——差异10倍。

从上下文工程的角度来看，改进KV缓存命中率涉及几个关键实践：

**保持你的提示前缀稳定**。由于LLM的确定性性质，即使是单令牌差异也会使缓存从该令牌开始失效。一个常见的错误是在系统提示的开头包含时间戳——特别是一个精确到秒的。当然，它让模型告诉你当前时间，但它也杀死了你的缓存命中率。

**让你的上下文仅追加**。避免修改以前的操作或观察。确保你的序列化是确定性的。许多编程语言和库在序列化JSON对象时不保证稳定的键顺序，这可能会无声地破坏缓存。

**在需要时显式标记缓存断点**。一些模型提供者或推理框架不支持自动增量前缀缓存，而是需要在上下文中手动插入缓存断点。分配这些时，考虑潜在的缓存过期，至少确保断点包含系统提示的结束。

此外，如果你使用LLama这样的框架自托管模型，确保启用了KV缓存，并且你正在使用会话ID等技术来跨分布式工作者一致地路由请求。

### 遮盖，不删除

随着你的代理获得更多能力，其动作空间自然变得更复杂——简单来说，工具的数量爆炸。最近多协议的受欢迎程度只会增加燃料。如果你允许用户可配置工具，相信我：有人最终会将数百个神秘工具插入你精心策划的动作空间。结果，模型更可能选择错误的动作或采取低效的路径。简而言之，你武装精良的代理变得更愚蠢。

一个自然的反应是设计一个动态动作空间——也许使用类似按需加载工具。我们也在Manus中尝试过那个。但我们的实验表明一个清晰的规则：除非绝对必要，避免在迭代中期动态添加或删除工具。有两个主要原因：

在大多数LLM中，工具定义在序列化后的上下文前面生存，通常在系统提示之前或之后。所以任何改变将使所有后续操作和观察的KV缓存失效。

当以前的操作和观察仍然引用在当前上下文中不再定义的工具时，模型变得困惑。没有适当的引导，这通常导致模式违反或幻想动作。

为了解决这个问题同时仍然改进动作选择，Manus使用了一个上下文感知的约束解码来管理工具可用性。它不是删除工具，而是在解码期间遮盖令牌logits以根据当前上下文防止（或强制）某些动作的选择。

实际上，大多数模型提供者和推理框架支持某种形式的响应前缀填充，允许你在不修改工具定义的情况下约束动作空间。通常有三种函数调用模式（我们将使用来自NousResearch的例子）：

**自动** – 模型可能选择调用函数或不调用。通过仅前缀填充响应前缀实现：`<|im_start|>assistant`

**必需** – 模型必须调用函数，但选择不受限制。通过前缀填充到工具调用令牌实现：`<|im_start|>assistant<tool_call>`

**指定** – 模型必须调用来自特定子集的函数。通过前缀填充到函数名的开头实现：`<|im_start|>assistant<tool_call>{"name": "browser_`

使用这个，我们通过直接遮盖令牌logits来约束动作选择。例如，当用户提供新的输入时，Manus必须立即回复而不是采取动作。我们也故意设计了具有一致前缀的动作名称——例如，所有浏览器相关工具以browser_开头，命令行工具以shell_开头。这允许我们轻松强制代理只在给定状态选择来自某个工具组的工具，而无需使用有状态的logits处理器。

这些设计帮助确保Manus代理循环保持稳定——即使在一个模型驱动的架构下。

### 使用文件系统作为上下文

现代前沿LLM现在提供128K令牌或更多的上下文窗口。但在真实世界的代理场景中，那通常还不够，有时甚至是一个负债。有三个常见的痛点：

观察可以是巨大的，特别是当代理与诸如网页或PDF的非结构化数据交互时。很容易超过上下文限制。

模型性能倾向于随着上下文长度进一步衰退，即使窗口技术上支持它。

长输入很昂贵，即使使用前缀缓存。你仍然在支付传输和前缀填充每个令牌的费用。

为了处理这个，许多代理系统实现上下文截断或压缩策略。但过度激进的压缩必然导致信息丧失。问题是基础性的：代理，按性质，必须根据所有先前的状态预测下一个动作——你不能可靠地预测哪个观察可能在十步后变得关键。从逻辑立场来看，任何不可逆的压缩都携带风险。

这就是为什么我们在Manus中将文件系统视为最终上下文：大小无限，按性质持久，并直接由代理操作。模型学会根据需要写入和读取文件——使用文件系统不仅仅作为存储，而是作为结构化、外部化的记忆。

我们的压缩策略总是设计为可恢复的。例如，网页的内容可以从上下文中删除，只要URL被保留，文档的内容可以被省略，如果其路径在沙箱中仍然可用。这允许Manus缩小上下文长度而不会永久丧失信息。

在开发这个功能时，我发现自己在想象让状态空间模型（SSM）在代理设置中有效工作需要什么。与Transformers不同，SSM缺乏完全注意力并与长范围向后依赖关系struggle。但如果他们能掌握基于文件的记忆——外部化长期状态而不是在上下文中持有它——那么他们的速度和效率可能解锁一个新的代理类。代理SSM可能是Transformers的真正继承者。

### 通过背诵操纵注意力

如果你使用过Manus，你可能注意到了一些有趣的东西：处理复杂任务时，它倾向于创建一个todo.md文件——并在任务进展时逐步更新它，检查已完成的项目。

那不仅仅是可爱的行为——这是一个故意的注意力操纵机制。

Manus中的典型任务平均需要大约50个工具调用。那是一个长循环——由于Manus依赖LLM进行决策制定，它容易漂移离题或忘记早期目标，特别是在长上下文或复杂任务中。

通过不断改写待办事项列表，Manus正在将其目标背诵到上下文的末端。这将全局计划推入模型的最近注意力跨度，避免"迷失在中间"问题并减少目标不一致。实际上，它正在使用自然语言来偏向其自己的焦点朝向任务目标——无需特殊的架构改变。

### 保留错误的东西

代理犯错误。那不是一个错误——这是现实。语言模型出现幻觉，环境返回错误，外部工具表现不良，意外的边缘情况显现出来。在多步骤任务中，失败不是例外；这是循环的一部分。

然而，一个常见的冲动是隐藏这些错误：清理追踪，重试动作，或重置模型的状态并将其留给魔幻的""。那感觉更安全，更受控。但它有个代价：删除失败删除证据。而没有证据，模型不能适应。

在我们的经验中，改进代理行为的最有效方式之一令人欺骗性地简单：将错误的回合保留在上下文中。当模型看到失败的动作——以及所得的观察或堆栈追踪——它隐含地更新其内部信念。这将其prior从类似的动作移开，减少重复相同错误的机会。实际上，我们相信错误恢复是真正代理行为的最清晰指标。然而在大多数学术工作和公共基准中，它仍然代表不足，这通常关注理想条件下的任务成功。

### 不要自己少样本

少样本是一个改进LLM输出的常见技术。但在代理系统中，它可以以微妙的方式反弹。

语言模型非常善于模仿；他们模仿上下文中的行为模式。如果你的上下文充满了类似的过去动作-观察对，模型将倾向于遵循该模式，即使它不再是最优的。

这可能在涉及重复决策或动作的任务中危险。例如，当使用Manus帮助审查一批20份简历时，代理通常陷入节奏——仅因为这是它在上下文中看到的而重复类似的动作。这导致漂移、过度概括或有时幻觉。

修复是增加多样性。Manus在动作和观察中引入少量的结构化变化——不同的序列化模板、替代措辞、秩序或格式的小噪声。这个受控的随机性帮助打破模式并调整模型的注意力。换句话说，不要少样本自己进入一个轨道。你的上下文越均匀，你的代理变得越脆弱。

### 结论

上下文工程仍然是一个新兴的科学——但对于代理系统，它已经至关重要。模型可能变得更强大、更快、更便宜，但没有一个原始能力的数量替代对记忆、环境和反馈的需求。你如何形成上下文最终定义了你的代理如何表现：它如何快速运行，它如何恢复，以及它如何远而扩展。

在Manus，我们通过反复重写、死亡末端和现实世界测试在数百万用户中学到了这些教训。我们在这里分享的没有一个是通用真理——但这些是对我们有效的模式。如果它们帮助你避免即使一个痛苦的迭代，那么这篇文章做了它的工作。

代理未来将被一次一个上下文地构建。好好工程化它们。

---

**翻译进度：** 第1、2、3篇完成 ✓

---

## 第四篇：广泛研究：超越上下文窗口

AI驱动研究的承诺一直很有吸引力：将繁琐的信息收集和综合工作委托给一个智能系统，释放人类认知来进行高阶分析和决策制定。然而，任何人在非平凡用例上推动这些系统的人都遇到了一个令人沮丧的现实：到第八或第九个多主题研究任务中，AI开始捏造。

不仅仅是简化。不仅仅是更简洁的总结。捏造。

这不是提示工程问题。这不是模型能力问题。这是一个架构约束，它安静地限制了AI研究工具的效用自其起源以来。而正是这个约束Wide Research设计来克服。

### 上下文窗口：一个基础瓶颈

每个大语言模型在上下文窗口内操作，一个有限的记忆缓冲区，限制了模型在任何给定时刻能够主动处理的信息量。现代模型已经令人印象深刻地推动了这个边界：从4K令牌到32K、128K，甚至最近版本中的1M令牌。

然而问题仍然存在。

当你要求AI研究多个实体——比如说，50家公司、30份研究论文或20个竞争产品——上下文窗口很快填满。这不仅仅是每个实体的原始信息，而是也：

- 原始任务规格和要求
- 一致输出格式化的结构模板
- 每个项目的中间推理和分析
- 交叉引用和比较笔记
- 所有先前项目的累积上下文

到模型到达第八或第九个项目时，上下文窗口在巨大的压力下。模型面临一个不可能的选择：明确失败，或开始偷工减料。

它总是选择后者。

### 捏造阈值

这是在实践中发生的情况：

- **项目1-5**：模型执行真正的研究。它检索信息、交叉引用来源和产生详细、准确的分析。
- **项目6-8**：质量开始微妙地衰退。描述变得稍微更通用。模型开始依赖于之前的模式而不是新鲜研究。
- **项目9+**：模型进入捏造模式。无法在维持彻底研究的认知负荷同时管理溢出上下文，它开始基于统计模式生成可信的内容，而不是真实的调查。

这些捏造是老练的。他们听起来权威。他们完美遵循既建立的格式。他们通常在语法上是完美的，在风格上与早期的合法条目一致。

他们也经常是错的。

竞争分析可能将功能分配给不提供的公司。文献审查可能引用有虚构发现的论文。产品比较可能发明不存在的定价等级或规格。

最可怕的部分是这些捏造很难检测到，没有手动验证——这违反了自动研究的整个目的。

### 为什么更大的上下文窗口不能解决这个

直观的反应是简单地扩展上下文窗口。如果32K令牌不足够，使用128K。如果那不足够，推送到200K或更远。

这个方法误解了问题。

首先，上下文衰退不是二进制的。一个模型不会在其整个上下文窗口中保持完美的回忆。研究表明检索准确性随与当前位置的距离衰退——"迷失在中间"现象。信息在上下文的开头和末尾被回忆得更可靠，而不是中间的信息。

其次，处理成本不成比例地增长。处理400K令牌上下文的成本不仅仅是200K的两倍——它在时间和计算资源中指数级增加。这使得大量上下文处理对许多用例经济上不可行。

第三，问题是认知负荷。即使具有无限上下文，要求单一模型跨打击的二十多个独立研究任务保持一致质量创建了一个认知瓶颈。模型必须不断地在项目之间切换上下文、维护一个比较框架、并确保风格一致性——同时执行核心研究任务。

第四，上下文长度压力。模型的"耐心"在某种程度上由样本中的长度分布在其训练数据中确定。然而，当前语言模型的后训练数据混合仍然由相对较短的轨迹主导，为聊天机器人风格的交互设计。结果，当助理消息的内容长度超过某个阈值时，模型自然会经历一种上下文长度压力的种类，促使它加快走向总结或诉诸于不完整的表达形式，例如项目符号列表。

上下文窗口是一个约束，是的。但这是一个更深层架构限制的症状：单处理器、顺序范式。

### 架构转变：平行处理

Wide Research代表了对AI系统应该如何接近大规模研究任务的基础重新思考。而不是要求一个处理器处理n个项目顺序地，我们部署n个平行的子代理来同时处理n个项目。

**Wide Research架构**

当你启动Wide Research任务时，系统运作如下：

**1. 智能分解**

主控制器分析你的请求并将其分解为独立的、可平行化的子任务。这涉及理解任务结构、识别依赖关系和创建连贯的子规格。

**2. 子代理委派**

对于每个子任务，系统启动一个专门的子代理。至关重要的是，这些不是轻量级流程——他们是全功能的Manus实例，每个具有：

- 一个完整的虚拟机环境
- 访问完整工具库（搜索、浏览、代码执行、文件处理）
- 一个独立的互联网连接
- 一个新鲜、空的上下文窗口

**3. 平行执行**

所有子代理同时执行。每个一个专注于排他在其分配的项目上，执行它对单一项目任务的相同深度的研究和分析。

**4. 集中协调**

主控制器保持监督，收集子代理完成工作时的结果。重要的是，子代理不相互通信，所有协调流过主控制器。这防止了上下文污染并保持独立。

**5. 合成和整合**

一旦所有子代理已报告回来，主控制器将结果合成到一个单一的、连贯的和全面的报告中。这个合成步骤利用了主控制器的完整上下文容量，因为它不负担原始研究努力。

### 为什么这改变了一切

**大规模一致质量**

每个项目得到相同的处理。第50项被充分研究与第一项一样。没有衰退曲线、没有捏造阈值、没有质量悬崖。

**真正的水平可扩展性**

需要分析10个项目？系统部署10个子代理。需要分析500？它部署500。架构线性地随任务大小缩放，而不是像基于上下文的方法一样指数级。

**显著的加速**

因为子代理并行操作，分析50个项目所需的真实世界时间大约与分析5个相同。瓶颈从顺序处理时间转移到合成时间——一个小得多的组件。

**降低幻觉率**

每个子代理在其认知舒适区内操作。有一个新鲜上下文和单一、专注的任务，没有压力来捏造。子代理可以执行真正的研究、验证事实和保持准确。

**独立性和可靠性**

因为子代理不共享上下文，一个子代理工作中的错误或幻觉不会传播到其他。每个分析独立站立，减少系统风险。

### 超越单处理器范式

Wide Research不仅仅是一个功能——它代表从单处理器范式和朝向一个编排的、平行的架构的基础转变。AI系统的未来不在于某一时刻更大的上下文窗口，而在于智能任务分解和平行执行。

我们从"AI助手"的时代转向"AI工作力"的时代。

**何时使用Wide Research**：任何涉及多个、相似项目的任务，需要一致分析——竞争研究、文献审查、批量处理、多资产生成。

**何时不使用**：深度顺序任务，其中每一步深度依赖于先前的结果，或小任务（少于10个项目），单处理器处理更具成本效益。

---

**翻译进度：** 第1-4篇完成 ✓

---

## 第五篇：我们如何构建多代理研究系统

**发布日期：** 2025年6月13日

我们的研究功能使用多个Claude代理来更有效地探索复杂主题。我们分享了构建这个系统的工程挑战和我们学到的教训。

Claude现在具有研究能力，允许它在网络、Google Workspace和任何集成中搜索来完成复杂任务。

从原型到生产的这个多代理系统的旅程教会了我们关于系统架构、工具设计和提示工程的关键教训。多代理系统由多个代理（LLM自主在循环中使用工具）组成，相互合作。我们的研究功能涉及基于用户查询规划研究过程的一个代理，然后使用工具创建平行代理来同时搜索信息。具有多个代理的系统在代理协调、评估和可靠性中引入了新挑战。

这篇文章分解了对我们有效的原则——我们希望你会发现它们在构建自己的多代理系统时很有用。

### 多代理系统的好处

研究工作涉及开放式问题，其中非常难以提前预测所需的步骤。你不能为探索复杂主题硬编码一个固定路径，因为该过程本质上是动态的、与路径相关的。当人们进行研究时，他们倾向于基于发现不断更新他们的方法，跟随在调查过程中出现的线索。

这种不可预测性使AI代理特别适合研究任务。研究要求灵活性来转向或探索调查中出现的接线。模型必须为许多回合自主操作，基于中间发现做出关于哪些方向追逐的决定。线性、一次性管道无法处理这些任务。

搜索的本质是压缩：从巨大的语料库中提取见解。子代理通过并行操作他们自己的上下文窗口、同时探索问题的不同方面然后在整合最重要的令牌对主导研究代理来方便压缩。每个子代理也提供关注点分离——不同的工具、提示和探索轨迹——这减少了路径依赖并启用了彻底、独立的调查。

一旦智能达到一个阈值，多代理系统成为扩展性能的必要方式。例如，尽管个人人类在过去100,000年中已经变得更加聪慧，人类社会在信息时代变得指数级更有能力，因为我们的集体智能和协调能力。即使通常聪慧的代理也面临当作为个人操作时的限制；代理组能够完成远超。

我们的内部评估显示多代理研究系统特别在涉及同时追求多个独立方向的广泛优先查询中表现出色。我们发现一个多代理系统具有Claude Opus 4作为主导代理和Claude Sonnet 4子代理在我们的内部研究评估中表现优于单代理Claude Opus 4 90.2%。例如，当要求识别信息技术S&P 500中的公司的所有董事会成员时，多代理系统通过为子代理分解这个为任务而发现正确的答案，而单代理系统失败于用缓慢的、顺序的搜索找到答案。

多代理系统工作主要是因为他们帮助花费足够的令牌来解决问题。在我们的分析中，三个因素解释了BrowseComp评估中95%的性能方差（这测试了浏览代理定位难以发现信息的能力）。我们发现令牌使用本身解释了80%的方差，工具调用的数量和模型选择是其他两个解释因素。这个发现验证了我们的架构，在代理中分布工作给具有独立上下文窗口的代理添加了更多的平行推理能力。最新的Claude模型充当在令牌使用上的大效率乘数，因为升级到Claude Sonnet 4是比在Claude Sonnet 3.7上倍增令牌预算更大的性能获得。多代理架构有效地为超过单一代理限制的任务扩展令牌使用。

有一个缺点：在实践中，这些架构快速烧过令牌。在我们的数据中，代理通常使用大约聊天互动的4倍令牌，多代理系统使用聊天的大约15倍令牌。为了经济可行性，多代理系统需要任务的值足够高来支付增加的性能。此外，某些需要所有代理共享相同上下文或涉及代理之间许多依赖关系的领域不是多代理系统今天的好匹配。例如，大多数编码任务涉及比研究更少的真正平行化任务，LLM代理还不太擅长实时协调和委派到其他代理。我们发现多代理系统在涉及重度平行化、超过单个上下文窗口的信息和与众多复杂工具交互的有价值任务中表现出色。

### 研究的架构概览

我们的研究系统使用一个多代理架构与编排者-工作者模式，一个主导代理协调该过程，同时委派给专门的子代理并行操作。

当用户提交查询时，主导代理分析它、开发一个策略和生成子代理来同时探索不同的方面。如上图所示，子代理充当智能过滤器，通过迭代使用搜索工具来收集信息，在这个实例中关于2025年AI代理公司，然后将一个公司列表返回到主导代理，以便它可以编译一个最终答案。

与RAG相反，使用静态检索。即，他们获取一些最相似的块的集合到输入查询并使用这些块来生成响应。我们的架构使用一个多步骤搜索，动态找到相关信息、适应新发现和分析结果来阐述高质量答案。

当用户提交查询时，系统创建一个LeadResearcher代理进入迭代研究过程。LeadResearcher首先思考这个方法，将其计划保存到记忆中来保留上下文，因为如果上下文窗口超过200,000令牌它将被截断，重要的是保留计划。它然后创建具有特定研究任务的专门子代理。每个子代理独立执行网络搜索，使用交错思考来评估工具结果，并返回发现到LeadResearcher。LeadResearcher合成这些结果并决定是否需要更多研究——如果是，它可以创建额外子代理或完善其策略。一旦收集了足够的信息，系统退出研究循环并通过一个CitationAgent，其处理文件和研究报告来识别引用的特定位置。这确保所有索赔被适当归因于他们的来源。最后研究结果，完成引用，被返回给用户。

### 多代理研究系统的提示工程和评估

多代理系统与单代理系统有关键差异，包括协调复杂性的快速增长。早期代理犯了诸如为简单查询生成50个子代理、无止境地搜寻网络寻找不存在的来源和互相分心过度更新的错误。因为每个代理由提示指导，提示工程是我们改进这些行为的主要杠杆。以下是我们为代理学到的提示工程原则：

**思考像你的代理一样**

为了迭代提示，你必须理解他们的影响。为了帮助我们做这个，我们使用我们的控制台精确提示和工具从我们的系统构建模拟，然后逐步观察代理工作。这立即展示了故障模式：代理在已有足够结果时继续、使用过度啰嗦的搜索查询或选择不正确的工具。有效的提示依赖于开发对代理的准确心理模型，这可以使最有影响的改变变得明显。

**教编排者如何委派**

在我们的系统中，主导代理将查询分解为子任务并将其描述给子代理。每个子代理需要一个目标、输出格式、关于使用和要使用的工具的指导以及清晰的任务边界。没有详细的任务描述，代理重复工作、留下缝隙或无法找到必要的信息。我们开始允许主导代理给出简单、短指令，如"研究半导体短缺"，但发现这些指令通常模糊足够，子代理误解任务或执行与其他代理完全相同的搜索。例如，一个子代理探索2021年汽车芯片危机，而2个其他的复制工作调查当前2025供应链，没有有效的劳动分工。

**对查询复杂性调整努力**

代理苦苦挣扎来判断不同任务的合适努力，所以我们在提示中嵌入了缩放规则。简单事实发现需要仅1个代理与3-10工具调用、直接比较可能需要2-4子代理与10-15调用每个和复杂研究可能使用超过10子代理以清晰分割责任。这些明确的指南帮助主导代理有效地分配资源并防止过度投资在简单查询中，这在我们的早期版本中是一个常见故障模式。

**工具设计和选择很重要**

代理工具接口与人机接口一样关键。使用正确的工具是有效的——通常，这严格必要。例如，代理搜索网络以获取仅存在于Slack中的上下文是命中注定的。使用给代理模型访问外部工具的MCP服务器，这个问题复合，当代理遇到不可见工具与大幅变化质量的描述。我们给了我们的代理明确的启发式方法：例如，首先审查所有可用工具、将工具使用匹配到用户意图、搜索网络以获取宽泛的外部探索，或首选专门工具对通用的。坏工具描述可以将代理送下完全错误的路径，所以每个工具需要不同的目的和清晰的描述。

**让代理改进自己**

我们发现Claude 4模型可以是优异的提示工程师。当给了一个提示和一个故障模式，他们能够诊断为什么代理失败并建议改进。我们甚至创建了一个工具测试代理——当给了一个有缺陷的MCP工具时，它尝试使用工具然后改写工具描述来避免失败。通过数十次测试该工具，这个代理发现了关键细致差别和错误。这个改进工具人体工程学的过程导致了未来使用新描述的代理的任务完成时间减少40%，因为他们能够避免最多错误。

**从宽到窄开始**

搜索策略应该镜像专家人类研究：在深钻入细节前探索景观。代理经常默认为过度长、特定查询返回很少结果。我们抵抗了这个倾向通过提示代理从短、宽泛的查询开始、评估什么是可用的，然后逐步缩小焦点。

**指导思维过程**

扩展思维模式，导致Claude输出额外令牌在一个可见的思维过程中，可以作为一个可控制的草稿簿。主导代理使用思维来规划其方法、评估哪些工具适合任务、确定查询复杂性和子代理计数和定义每个子代理的角色。我们的测试显示扩展思维改进了指令跟随、推理和效率。子代理也计划，然后在工具结果后使用交错思维来评估质量、识别缝隙和完善他们的下一个查询。这使子代理更有效在适应任何任务。

**平行工具调用转换速度和性能**

复杂研究任务自然涉及探索许多来源。我们的早期代理执行了顺序搜索，其是痛苦地慢。为了获得速度，我们引入了两种平行化种类：(1)主导代理在平行中而不是顺序中启动3-5个子代理；(2)子代理使用3+工具在平行中。这些改变为复杂查询切割了研究时间多达90%，允许研究在分钟而不是小时中做更多工作同时覆盖比其他系统更多信息。

我们的提示策略关注于灌输好启发式方法而不是刚性规则。我们研究了技能人类如何方法研究任务并在我们的提示中编码了这些策略——如分解困难问题为较小的任务、仔细评估来源质量、基于新信息调整搜索方法和识别何时关注深度（详细调查一个主题）对广泛（探索许多主题在平行中）。我们也主动缓和了意外的侧效应通过设置明确的防卫来防止代理螺旋无法控制。最后，我们专注于与可观察性和测试实例的快速迭代循环。

### 代理的有效评估

好评估对建立可靠的AI应用至关重要，代理也不例外。然而，评估多代理系统呈现独特的挑战。传统评估经常假设AI遵循相同的步骤每一次：给定输入X，系统应遵循路径Y来产生输出Z。但多代理系统不那样工作。即使与相同的起点，代理可能采取完全不同的有效路径来达到他们的目标。一个代理可能搜索三个来源，而另一个搜索十个，或他们可能使用不同的工具来找到相同的答案。因为我们不总是知道正确的步骤是什么，我们通常不能仅检查代理是否遵循了我们事先规定的"正确"步骤。相反，我们需要灵活的评估方法来判断代理是否达到了正确的结果同时也遵循了一个合理的过程。

**立即用小样本开始评估**

在早期代理开发中，改变倾向于有巨大的影响，因为有丰富的低挂果。提示调整可能从30%提升成功率到80%。有这么大的影响尺寸，你能用仅仅几个测试实例发现改变。我们开始与大约20个查询的集合代表真实使用模式。测试这些查询经常允许我们清楚地看到改变的影响。我们经常听说AI开发者团队延迟创建评估，因为他们相信仅大评估与数百个测试实例是有用的。然而，最好是立即开始用小规模测试用仅仅几个例子，而不是延迟直到你能构建更彻底的评估。

**LLM作为评估员当做得好时缩放**

研究输出很难进行程序评估，因为他们是自由格式的文本并且很少有单一的正确答案。LLM是评分输出的自然适配。我们使用了一个评估LLM对抗一个问卷标准的每个输出：事实准确性（索赔是否匹配来源？）、引用准确性（引用的来源是否匹配索赔？）、完整性（被请求的所有方面是否被覆盖？）、来源质量（它是否使用了对低质量次来源的主要来源？）和工具效率（它是否以合理的次数使用了正确的工具？）。我们实验了多个评估者来评估每个分量，但发现一个输出分数从0.0-1.0和通过/不通过等级的单一LLM调用用一个单一提示最一致并与人类判断一致。这个方法特别有效当评估测试实例确实有一个清晰的答案，我们可以使用LLM评估者来简单地检查如果答案是正确的（即它是否准确列出了药房公司与前3最大的R&D预算？）。使用LLM作为评估者允许我们可扩展地评估数百个输出。

**人类评估捕获什么自动化错过**

人们测试代理发现评估错过的边际情况。这些包括对不寻常的查询幻想的答案、系统故障或微妙的来源选择偏差。在我们的实例中，人类测试者发现我们的早期代理一致地选择了对权威但较少排名的来源如学术PDF或个人博客的SEO优化内容农场。添加来源质量启发式方法到我们的提示帮助解决了这个问题。即使在自动评估的一个世界中，手动测试仍然是至关重要的。

多代理系统具有无法明确规划的出现行为。例如，对主导代理的小改变可以不可预测地改变子代理如何表现。成功需要理解交互模式，不仅仅是个别代理表现。因此，最好的提示对这些代理不仅仅是严格指令，而是定义劳动分工的合作框架、问题解决方法和努力预算。正确做这个依赖于仔细的提示和工具设计、坚实的启发式方法、可观察性和紧密的反馈循环。查看我们的食谱中的开源提示以从我们的系统举例提示。

### 生产可靠性和工程挑战

在传统软件中，一个错误可能破坏一个功能、降低性能或导致停机。在代理系统中，次要改变级联为大的行为改变，这使得写复杂的代码对必须在长时间运行的过程中保留状态的代理非常困难。

**代理是有状态的且错误复合**

代理可以运行很长的周期，维护跨许多工具调用的状态。这意味着我们需要可靠执行代码和沿路处理错误。没有有效的缓解，次要系统故障可以对代理是灾难性的。当错误发生时，我们不能仅仅从开始重新启动：重新启动很昂贵且令人沮丧对用户。相反，我们构建了系统可以从代理是当错误发生时恢复的地方。我们也使用模型的智能来优雅处理问题：例如，让代理知道工具在失败和允许它适应工作出奇地好。我们结合AI代理的适应性建立在Claude与确定性的防卫如重试逻辑和定期检查点。

**调试从新的方法获益**

代理进行动态决定且在运行之间是非确定性的，即使具有相同的提示。这使得调试更难。例如，用户会报告代理"不发现明显的信息"，但我们看不到为什么。代理是否使用坏搜索查询？选择贫乏的来源？击中工具故障？添加完整生产追踪让我们诊断为什么代理失败并系统地固定问题。超越标准可观察性，我们监控代理决定模式和交互结构——全部不监控个别对话的内容，以保留用户隐私。这个高级的可观察性帮助我们诊断根本原因、发现意外的行为和修复常见的故障。

**部署需要仔细的协调**

代理系统是提示、工具和执行逻辑的高度有状态的网。几乎持续运行。这意味着每当我们部署更新时，代理可能在他们的过程中的任何地方。我们因此需要防止我们的好意代码改变从破坏现存的代理。我们不能一次更新每个代理到新版本。相反，我们使用彩虹部署来避免中断运行代理，通过从旧到新版本逐步转移交通同时保存两个都在运行。

**同步执行创建瓶颈**

目前，我们的主导代理同步执行子代理，等待每个子代理集合完成然后继续。这简化了协调，但在代理之间的信息流中创建了瓶颈。例如，主导代理不能指导子代理、子代理不能协调和整个系统可以被阻止当等待单一子代理完成搜索。异步执行会启用额外的平行化：代理并发工作和创建新的子代理当需要。但这个异步性添加挑战在结果协调中、状态一致性和错误传播跨子代理。随着模型可以处理更长的和更复杂的研究任务，我们期望性能获得将证明复杂性。

### 结论

当构建AI代理时，最后一英里经常变成大多数旅程。在开发者机器上运作的代码库需要显著的工程变得可靠的生产系统。代理系统中错误的复合性质意味着对传统软件微不足道的问题可以完全误导代理。一个步骤失败可以导致代理探索完全不同的轨迹，导致不可预测的结果。对这篇文章描述的所有原因，原型和生产之间的间隙经常比预期更宽。

尽管这些挑战，多代理系统已经证明了对开放式研究任务有价值。用户已说Claude帮助了他们发现他们未考虑的业务机会、导航复杂的医疗保健选项、解决棘手的技术错误和通过发现他们独自不会发现的研究连接节约多达天的工作。多代理研究系统能够在规模上可靠地操作与仔细的工程、全面的测试、详细的提示和工具设计、强大的操作实践和对当前代理能力的强烈理解的紧密合作在研究、产品和工程团队中。我们已经看到这些系统转变了人们如何解决复杂的问题。

一个Clio嵌入地块显示了人们今天使用研究功能的最常见方式。排名靠前的使用场景分类是在专门领域中开发软件系统（10%）、开发和优化专业和技术内容（8%）、开发业务增长和收入生成策略（8%）、协助学术研究和教育材料开发（7%）和研究并核实关于人物、地方或组织的信息（5%）。

---

**翻译进度：** 第1-5篇完成 ✓

---

## 第六篇：为代理编写有效的工具——与代理合作

**发布日期：** 2025年9月11日

代理只能与我们给他们的工具一样有效。我们分享如何编写高质量工具和评估的最有效技术，以及你如何能通过使用Claude来优化它自己的工具来提升性能。

模型上下文协议（MCP）可以赋予LLM代理具有可能数百个工具来解决现实世界任务的能力。但我们如何让这些工具最大化有效呢？

在这篇文章中，我们描述了我们在各种代理AI系统中改进性能的最有效技术。

我们通过涵盖如何开始：

- 构建和测试你的工具的原型
- 创建和运行代理工具的全面评估
- 与Claude Code之类的代理合作来自动增加你的工具的性能

我们以我们已经识别的关键原则进行结束来编写高质量的工具：

- 选择正确的工具来实现（以及不实现的）
- 命名空间工具来在功能中定义清晰的边界
- 返回有意义的上下文从工具回到代理
- 优化工具响应的令牌效率
- 提示工程工具描述和规格

通过选择对工具的使用进行评估来增加代理工具的性能。你可以使用Claude Code来自动针对此评估优化你的工具。

### 什么是工具？

在计算中，确定性系统用相同的输入产生相同的输出每一次，而非确定性系统——如代理——可以生成不同的响应即使具有相同的起点。

当我们传统地编写软件时，我们在确定性系统之间建立了一个合约。例如，一个函数调用如getWeather("NYC")将每一次以完全相同的方式获取纽约市的天气。

工具是一个新的软件种类，它反映了确定性系统和非确定性代理之间的一个合约。当用户要求"我应该今天带一个伞吗？"，一个代理可能调用天气工具、来自一般知识回答或甚至首先要求关于位置的澄清问题。偶尔，代理可能出现幻觉或甚至无法掌握如何使用一个工具。

这意味着从根本上重新思考我们的方法当为代理编写软件时：我们不应该为其他开发者或系统编写工具和MCP服务器，而是为代理设计他们。

我们的目标是增加代理能有效地在解决广泛的任务中通过使用工具来追逐各种各样的成功策略的表面。幸运地，在我们的经验中，对代理最"人体工学"的工具也最终令人惊讶地直观来理解作为人类。

### 如何编写工具

在这个章节中，我们描述了你如何能与代理合作既来编写并改进你给他们的工具。通过立即站起一个快速原型的你的工具并测试他们当地开始。接下来，运行一个全面的评估来测量后续改变。与代理合作，你可以重复改进并评估你的工具的过程直到你的代理在现实世界任务上达到强性能。

**构建一个原型**

不获得第一手体验就很难预期哪些工具代理将发现人体工学和哪些代理不会。通过站起一个快速原型的你的工具开始。如果你正在使用Claude Code来编写你的工具（可能在一次射中），它帮助给Claude任何软件库、API或SDK（包括可能的MCP SDK）你的工具将依赖的文档。LLM友好的文档可以常见被发现在官方文件网站上在平面llms.txt文件中（这里是我们API的一个）。

将你的工具包裹在一个本地MCP服务器或桌面扩展（DXT）中将允许你连接并在Claude Code或Claude桌面应用中测试你的工具。

为了连接你的本地MCP服务器到Claude Code，运行claude mcp add <name> <command> [args...]。

为了连接你的本地MCP服务器或DXT到Claude桌面应用，导航到设置>开发者或设置>扩展，分别。

工具也能被直接传递到Anthropic API调用中来进行程序化测试。

自己测试工具来识别任何粗糙边缘。从你的用户收集反馈来构建一个直观关于你期望的使用实例和提示的。

**运行一个评估**

接下来，你需要测量Claude如何好地使用你的工具通过运行一个评估。通过生成许多评估任务开始，接地在现实世界用途中。我们推荐与代理合作来帮助分析你的结果和确定如何改进你的工具。在我们的工具评估食谱中看到这个过程端到端。

这个图表测量人类编写对比Claude优化的Slack MCP服务器的测试集准确性。

我们的内部Slack工具的保留测试集性能。

**生成评估任务**

具有你的早期原型，Claude Code能快速探索你的工具并创建打几十个提示和响应对。提示应该受现实世界使用启发并基于现实的数据来源和服务（例如，内部知识库和微服务）。我们推荐你避免过度简化或肤浅的"沙箱"环境不为足够的复杂性压力测试你的工具。强评估任务可能需要多个工具调用——可能打几十。

这些是强任务的一些例子：

- 下周为了讨论我们最新的Acme Corp项目与Jane安排一次会议。附上我们最后项目规划会议的笔记并保留一间会议室。
- 客户ID 9182报告他们被为单一购买尝试充电了三次。发现所有相关的日志条目并确定是否任何其他顾客受到影响相同的问题。
- 客户Sarah Chen刚提交了一个取消请求。准备一个保留报价。确定：(1)为什么他们离开，(2)什么保留报价将是最引人注目的，和(3)任何风险因素我们应该在做一个报价前知道。

并且这些是弱任务的一些例子：

- 下周为jane@acme.corp安排一次会议。
- 搜索支付日志以进行purchase_complete和customer_id=9182。
- 按客户ID 45892发现取消请求。

每个评估提示应该与一个可验证的响应或结果配对。你的验证器可以与一个精确的字符串比较一样简单作为基础真理和采样响应之间，或作为高级为征募Claude来判断响应。避免过度严格的验证者拒绝正确的响应由于虚假差异如格式化、标点或有效的替代措辞。

对于每个提示-响应对，你可以选择也指定代理你期望在解决任务中调用来测量代理是否成功地掌握了每个工具的目的在评估期间。但是，因为可能有多个有效的路径来正确解决任务，尝试避免过度指定或过度适配到策略。

**运行评估**

我们推荐以程序化方式运行你的评估与直接LLM API调用。使用简单的代理循环（while循环包裹交替LLM API和工具调用）：一个循环对于每个评估任务。每个评估代理应该被给一个单一的任务提示和你的工具。

在你的评估代理的系统提示中，我们推荐指导代理输出不仅仅结构化响应块（对于验证）而且推理和反馈块。指导代理输出这些在工具调用之前和响应块可能增加LLM的有效智能通过触发链式思维（CoT）行为。

如果你正在用Claude运行你的评估，你可以为类似的功能打开交错思维"现成的"。这将帮助你探查为什么代理做或不调用某些工具和突出改进的特定区域在工具描述和规格中。

同样如顶级准确性，我们推荐收集其他指标如个别工具调用和任务的总运行时间、总工具调用数、总令牌消耗和工具错误。追踪工具调用可以帮助显示代理追逐的常见工作流并提供一些机会对于工具来合并。

这个图表测量人类编写对比Claude优化的Asana MCP服务器的测试集准确性。

我们的内部Asana工具的保留测试集性能。

**分析结果**

代理是你有用的伙伴在发现问题和提供关于从矛盾的工具描述到低效的工具实现和困惑的工具模式的所有事物反馈。但是，保持在思维中代理在他们的反馈和响应中省略的什么可以经常比他们包含的更加重要。LLM不总是说什么他们意思。

观察你的代理变得卡住或困惑的地方。读通过你的评估代理的推理和反馈（或CoT）来识别粗糙边缘。审查原始文字记录（包括工具调用和工具响应）来捕获代理不在代理的CoT中明确描述的任何行为。在线阅读；记住你的评估代理不一定知道正确的答案和策略。

分析你的工具调用指标。许多冗余工具调用可能建议一些分页的右调整大小或令牌限制参数有价值；许多工具错误对于无效参数可能建议工具可以使用更清晰的描述或更好的例子。当我们推出Claude的网络搜索工具时，我们识别Claude不必要地附加了2025到工具的查询参数，偏置搜索结果并贬低性能（我们通过改进工具描述中指导Claude朝向正确的方向）。

**与代理合作**

你甚至可以让代理分析你的结果并为你改进你的工具。简单地连接来自你的评估代理的文字记录并粘贴他们到Claude Code中。Claude是出色的在分析文字记录和一次重构许多工具——例如，来确保工具实现和描述在做新改变时保持自我一致。

实际上，大多数这篇文章中的建议来自反复优化我们的内部工具实现与Claude Code。我们的评估在我们的内部工作空间的顶部被创建，镜像了我们的内部工作流的复杂性，包括真实的项目、文件和消息。

我们依赖保留的测试集来确保我们没有过度适配到我们的"训练"评估。这些测试集显示我们能提取额外的性能改进即使超出我们用"专家"工具实现达成的——无论这些工具是手动编写的由我们的研究人员或由Claude本身生成的。

在下一个章节中，我们将分享一些我们从这个过程学到的。

**为代理编写有效工具的原则**

在这个章节中，我们将我们的学习蒸馏为几个指导原则来编写有效的工具。

**为代理选择正确的工具**

更多的工具并不总是导致更好的结果。一个常见的错误我们已观察是简单包装现有软件功能或API端点的工具——无论或工具是否对代理适当。这是因为代理具有不同的"affordances"对于传统软件——即，他们具有不同的方式来感知他们能采取具有这些工具的潜在行为。

LLM代理具有有限的"上下文"（即，有对多少信息他们可以一次处理的限制），然而计算机记忆是便宜的且丰富的。考虑在地址书中搜索联系人的任务。传统软件程序可以有效地存储和处理一个联系人列表一次，在移动到下一个之前检查每一个。

但是，如果一个LLM代理使用一个返回所有联系人然后必须逐令牌阅读通过每一个的工具，它浪费了它的有限上下文空间在不相关的信息上（想象通过从顶部到底部阅读每一页搜索你的地址书中的一个联系人——即，通过蛮力搜索）。更好的且更自然的方法（对于代理和人类两者）是首先跳到相关的页面（也许通过字母上发现它）。

我们推荐构建几个周到的工具针对特定的高影响工作流，其匹配你的评估任务并从那里扩展。在地址书的实例中，你可能选择实现一个search_contacts或message_contact工具而不是list_contacts工具。

工具可以合并功能，处理潜在的多个离散的操作（或API调用）在引擎盖下。例如，工具能够用相关的元数据丰富工具响应或处理频繁链接、多步任务在一个单一的工具调用中。

这些是一些例子：

- 而不是实现一个list_users、list_events和create_event工具，考虑实现一个schedule_event工具，其发现可用性和安排一个事件。
- 而不是实现一个read_logs工具，考虑实现一个search_logs工具，其仅返回相关的日志行和一些周围的上下文。
- 而不是实现get_customer_by_id、list_transactions和list_notes工具，实现一个get_customer_context工具，其编译所有一个顾客的最近的&相关信息一次。

确保每个工具你构建具有一个清晰、不同的目的。工具应该启用代理来细分和解决任务在相同的方式一个人类会，给予访问相同的基础资源，并同时减少中间输出会的其他方式消耗的上下文。

太多个工具或重叠工具也能分散代理从追求高效策略。精心、选择的规划工具你构建（或不构建）能真的付出。

**命名空间你的工具**

你的AI代理将可能获得访问打几十个MCP服务器和数百个不同的工具——包括由其他开发者。当工具重叠在函数中或具有模糊的目的时，代理能变得困惑关于哪些要使用。

命名空间（在常见前缀下分组相关工具）能帮助描述许多工具之间的边界；MCP客户端有时默认做这个。例如，按服务命名空间工具（例如，asana_search、jira_search）和按资源（例如，asana_projects_search、asana_users_search）能帮助代理在正确的时间选择正确的工具。

我们已发现选择之间前缀和后缀基础的命名在我们的工具使用评估中具有非平凡的影响。影响由LLM变化，并且我们鼓励你根据你自己的评估选择一个命名方案。

代理可能调用错误的工具，用错误的参数调用正确的工具、调用太少工具或不当地处理工具响应。通过选择性地实现工具的名称其中反映任务的自然细分，你同时减少加载到代理的上下文中的工具数和工具描述并将代理计算从代理的上下文回到工具调用本身。这减少了代理的整体风险犯错误的。

**从你的工具返回有意义的上下文**

在相同的线条中，工具实现应该照顾到仅返回高信号信息回代理。他们应该优先情境相关性上灵活性，并避免低级别的技术标识符（例如：uuid、256px_image_url、mime_type）。字段如名称、image_url和file_type要比直接更可能知道代理的下游行为和响应。

代理也倾向于与自然语言名字、条款或标识符成功地搏斗显著比他们用与秘密的标识符。我们已发现仅解析任意的字母数字UUID到更语义有意义且可解释的语言（或甚至一个0索引的ID方案）显著改进Claude的检索任务精度通过减少幻觉。

在一些实例中，代理可能需要与自然语言和技术标识符输出两者交互的灵活性，如果仅触发下游工具调用（例如，search_user(name='jane')→send_message(id=12345)）。你能通过在你的工具中暴露一个简单的response_format enum参数来启用两者，允许你的代理控制工具是否返回"简洁"或"详细"响应（下面的图像）。

你能添加更多的格式来甚至更大的灵活性，相似到GraphQL其中你能选择准确地哪些信息片段你想要接收。这里是一个例子ResponseFormat enum来控制工具响应详细程度：

```
enum ResponseFormat {
   DETAILED = "detailed",
   CONCISE = "concise"
}
```

一个详细工具响应的例子（206令牌）。

一个简洁工具响应的例子（72令牌）。

Slack线程和线程回复由唯一的thread_ts识别，需要获取线程回复。thread_ts和其他ID（channel_id、user_id）能从一个"详细"工具响应中被检索来启用进一步的工具调用，需要这些。"简洁"工具响应返回仅线程内容和排除ID。在这个例子中，我们使用大约1/3的令牌用"简洁"工具响应。

即使你的工具响应结构——例如XML、JSON或降价——能在评估性能中具有一个影响：没有一个尺寸适配全部的解决方案。这是因为LLM基于下一令牌预测被训练并倾向于与他们的训练数据相匹配的格式一起表现更好。最优的响应结构将由任务和代理大幅变化。我们鼓励你基于你自己的评估选择最好的响应结构。

**优化工具响应的令牌效率**

优化上下文质量很重要。但是优化返回给代理工具响应中的上下文的数量也是。

我们建议实现任何工具响应的分页、范围选择、过滤和/或截断的一些组合，其可以使用许多上下文带有合理的默认参数值。对于Claude Code，我们默认将工具响应限制为25,000令牌。我们期望代理的有效上下文长度随时间增长，但对于上下文高效的工具的需求保留。

如果你选择截断响应，确定指导代理与有用的指令。你能直接鼓励代理追求更多令牌高效的策略，如制作许多小的、目标的搜索而不是知识检索任务的一个单一、广泛的搜索。类似地，如果一个工具调用提升一个错误（例如，在输入验证期间），你能提示工程你的错误响应来清晰地通信特定和可行的改进，而不是模糊的错误代码或追踪。

一个截断工具响应的例子。

一个无用的错误响应的例子。

一个有用的错误响应的例子。

工具截断和错误响应能指导代理朝向更多令牌高效的工具使用行为（使用过滤或分页）或给例子正确格式化工具输入的。

**提示工程你的工具描述**

我们现在来到一个最有效的方法来改进工具之一：提示工程你的工具描述和规格。因为这些被加载到你的代理的上下文中，他们能集体指导代理朝向有效的工具调用行为。

当编写工具描述和规格时，思考你将如何描述你的工具到你的团队上的一个新员工。考虑你可能隐含地带来的上下文——专门的查询格式、利基术语的定义、基础资源之间的关系——并让它明确。通过清晰描述来避免歧义（和用严格的数据模型强制）期望的输入和输出。特别是，输入参数应该是明确命名的：而不是一个参数名为user，尝试一个参数名为user_id。

与你的评估你能用更大的信心测量你的提示工程的影响。甚至小的精致到工具描述能产生戏剧的改进。Claude Sonnet 3.5在SWE-bench验证的评估中达到最先进的性能在我们做了精确精致到工具描述后，戏剧地减少了错误率并改进了任务完成。

你能在我们的开发者指南中发现对工具定义的其他最佳实践。如果你正在为Claude构建工具，我们也推荐阅读关于工具如何被动态加载到Claude的系统提示的。最后，如果你正在为一个MCP服务器编写工具，工具注释帮助公开哪些工具需要开放世界访问或做破坏的改变。

### 前看

为代理构建有效工具，我们需要重新定向我们的软件开发实践从可预测的、确定性的模式到非确定性的。

通过我们在这篇文章中描述的迭代的、评估驱动的过程，我们已识别成功工具中的一致的模式：有效工具是有意识地和清晰地定义的，有判别地使用代理上下文，可以在不同的工作流中组合，并启用代理来直观地解决现实世界任务。

在未来，我们期望特定的机制通过代理与世界互动的进化——从对MCP协议的更新到对基础LLM本身的升级。用一个系统的、评估驱动的方法来改进代理的工具，我们能确保随着代理变得更有能力，他们使用的工具将随时间演变。

---

**翻译进度：** 第1-6篇完成 ✓

---

## 第七篇：AI代理的有效上下文工程

**发布日期：** 2025年9月29日

上下文是AI代理的一个关键但有限的资源。在这篇文章中，我们探索有效策划和管理赋予他们动力的上下文的策略。

在应用AI近几年专注于提示工程后，一个新的术语已获得突出：上下文工程。用语言模型构建正在变得更少关于找到正确的词和短语对于你的提示，以及更多关于回答更宽泛的问题"什么上下文配置最可能生成我们的模型所需的行为？"

上下文指的是当从大语言模型采样时包含的令牌集合。工程问题在手是优化这些令牌的效用对抗LLM的固有约束为了一致地达到一个所需的结果。有效地驾驭LLM通常需要在上下文中思考——换句话说：考虑代理任何给定时刻的全息状态以及该状态可能产生的潜在行为。

在这篇文章中，我们将探索新兴的上下文工程艺术和提供一个精细的心理模型来构建可导向的、有效的代理。

### 上下文工程对比提示工程

在Anthropic，我们将上下文工程视为提示工程的自然进展。提示工程指的是为最优的结果编写和组织LLM指令的方法（参见我们的文档对于概览和有用的提示工程策略）。上下文工程指的是在LLM推理期间策划和维护最优令牌集合（信息）的策略集合，包括所有其他可能降落在那里之外提示的信息。

在使用LLM工程的早期，提示是最大的AI工程工作组成部分，因为大多数使用实例之外的日常聊天交互需要对一次性分类或文本生成任务优化的提示。如术语所暗示，提示工程的主要焦点是如何编写有效的提示，特别是系统提示。但是，随着我们朝更有能力的代理转向，对多个推理回合运行且较长的时间视野，我们需要策略来管理整个上下文状态（系统指令、工具、模型上下文协议（MCP）、外部数据、消息历史等）。

一个代理在循环中运行生成越来越多的数据，其可能对下一个推理转向相关，以及这个信息必须循环精致。上下文工程是策划什么将进入有限上下文窗口的艺术与科学来自不断进化的可能信息的宇宙。

与离散提示编写相对，上下文工程是迭代的，策划阶段每一次发生我们决定什么传递到模型。

### 为什么上下文工程对构建有能力的代理很重要

尽管他们的速度和处理更大和更大的数据卷的能力，我们已观察LLM，如人类，在某一点失去焦点或经验困惑。在干草堆风格基准测试中的研究已发现上下文衰退的概念：当上下文窗口中的令牌数增加时，模型的能力准确回忆那个上下文的信息下降。

尽管某些模型表现比其他人更温柔的衰退，这个特征浮现跨所有模型。上下文，因此，必须被视为一个有限的资源具有递减的边际回报。如人类，其具有有限的工作记忆能力，LLM具有一个"注意力预算"，他们在解析大数量的上下文时绘制。每一个新令牌引入都通过某个数量耗尽这个预算，增加了仔细策划可对LLM可用令牌的需要。

这个注意力稀缺性源自LLM的架构约束。LLM基于转换器架构，其启用每一个令牌跨整个上下文对每其他令牌关注。这导致对于n令牌的n²成对关系。

随着其上下文长度增加，一个模型的能力捕获这些成对关系变得延伸稀薄，创建上下文大小和注意力焦点之间的自然张力。另外，模型从训练数据分布开发他们的注意力模式，其中较短的序列通常比较长的更常见。这意味着模型更少经验且更少专门的参数对于上下文宽的依赖关系。

技术如位置编码内插允许模型处理较长的序列通过适配他们到原本被训练的较小上下文，尽管伴随某种衰退在令牌位置理解中。这些因素创建一个性能梯度而不是硬崖：模型在较长上下文保持高度有能力但可能对较长上下文显示减少的精度来说信息检索和长范围推理与他们在较短上下文上的性能相比。

这些现实意味着周到的上下文工程对构建有能力的代理是至关重要的。

### 有效上下文的剖析

给定LLM被受限由有限的注意力预算，好的上下文工程意味着发现最小的可能的高信号令牌集合，其最大化到达某个所需结果的可能性。实现这个实践远比说的容易，但在下面的章节中，我们列举这个指导原则在实践中对上下文的不同组件意味着什么。

**系统提示**

系统提示应该非常清晰并使用简单、直接的语言来在代理的正确的海拔高度呈现想法。正确的海拔高度是两个常见的故障模式之间的金发姑娘区。在一个极端，我们看到工程师在他们的提示中硬编码复杂、脆弱的逻辑来激发精确的代理行为。这个方法创建脆弱性并随时间增加维护复杂性。在另一个极端，工程师有时提供模糊的、高级的指导失败给LLM明确的信号到所需的输出或错误地假设共享上下文。最优的海拔高度击中平衡：特定到有效地指导行为，然而灵活到提供模型以强启发式方法来指导行为。

在上下文工程中标定系统提示。

在谱的一个末端，我们看到脆弱如果-否则硬编码提示，在另一个末端我们看到提示，过度一般或错误地假设共享上下文。

我们推荐组织提示进不同的章节（像<background_information>、<instructions>、## 工具指导、## 输出描述等等）并使用像XML标记或降价标题这样的技术来描述这些章节，尽管确切的提示格式可能随着模型变得更有能力变得较少重要。

无论你如何决定结构你的系统提示，你应该努力朝向能完全叙述你的期望行为的最小信息集合。（注意最小不一定意味着短；你仍然需要提供给代理足够的信息确保它遵从期望的行为。）最好开始通过用最好的模型可用的最小提示测试来看它在你的任务上如何表现，然后基于初期测试发现的故障模式添加清晰的指令和例子来改进性能。

**工具**

工具允许代理与他们的环境操作并为他们工作拉入新的、附加的上下文。因为工具定义了代理和他们的信息/行为空间之间的合约，它是代理推动效率，两个通过返回令牌高效信息且通过鼓励高效代理行为的工具非常重要。

在为代理编写工具——与AI代理中，我们讨论了构建LLM理解得好且有最小功能重叠的工具。相似到良好设计代码库的功能，工具应该是自我包含的、健壮的错误，以及关于他们的目标使用非常清晰。输入参数应该类似地是描述性的、明确的和对模型的固有强项有利。

一个我们看到的最常见的故障模式是膨胀工具集涵盖太多的功能或导致关于哪个工具应该被使用的歧义决定点。如果一个人类工程师不能明确地说哪个工具应该在给定的情形中被使用，一个AI代理不能被期望做得更好。如我们稍后讨论的，策划一个最小可行的工具集对于代理也能导致更可靠的维护和策划的上下文长的交互。

**例子**

提供例子，以别的方式称为少样本提示，是一个众所周知的最佳实践我们继续强烈建议。但是，团队会经常在试图阐明LLM应该遵循的每可能规则的提示中放进堆积如山的边缘实例。我们不推荐这个。相反，我们推荐工作来策划一个多样的、正规的例子集合，其有效地描述代理的期望行为。对于一个LLM，例子是"图片"值一千个词。

我们跨上下文的不同组件的总体指导（系统提示、工具、例子、消息历史等）是思想并保持你的上下文知情但紧。现在让我们深入进入在运行时动态检索上下文。

### 上下文检索和代理搜索

在构建有效的AI代理中，我们突出了LLM工作流和代理之间的差异。自从我们写了那篇文章，我们已倾向朝向一个对代理的简单定义：LLM自主在循环中使用工具。

与我们的顾客工作，我们已看到该字段聚集在这个简单的范例上。随着基础模型变得更有能力，代理的自治水平能缩放：更聪慧的模型允许代理独立地导航细致的问题空间并从错误中恢复。

我们现在看到在工程师思考关于代理设计上下文的方式中的转变。今天，许多AI原生应用使用某种嵌入式基础推理时间检索来表面重要上下文对于代理来推理。随着字段转向更多代理的方法，我们越来越看到团队用"及时"上下文策略增加这些检索系统。

而不是预处理所有相关的数据提前，代理用"及时"方法维护轻量级标识符（文件路径、存储的查询、网络连接等）并使用这些引用来在运行时使用工具动态地将数据加载到上下文中。Anthropic的代理编码解决方案Claude Code使用这个方法来执行复杂的数据分析大数据库。模型能够编写目标查询、存储结果和杠杆Bash命令如头和尾来分析大量的数据而没有曾经加载完整的数据对象进入上下文。这个方法镜像人类认知：我们通常不记住整个信息库，而是引入外部组织和索引系统如文件系统、收件箱和书签来检索按需相关信息。

超越存储效率，这些引用的元数据提供一个机制来有效地精致行为，无论是显式提供还是直观。对于在文件系统中操作的代理，一个命名为test_utils.py在测试文件夹中的存在蕴含一个不同的目的相对一个带相同名字的文件在src/core_logic/文件夹中。文件夹层级、命名约定和时间戳都提供重要的信号帮助人类和代理两者理解如何以及何时利用信息。

让代理自主地导航和检索数据也启用渐进式公开——换句话说，允许代理通过探索逐步地发现相关上下文。每一个交互产生知道下一个决定的信息：文件大小建议复杂性；命名约定暗示目的；时间戳能是相关性的代理。代理能组装理解分层地，维护仅什么是必要在工作记忆中和杠杆笔记策略对于额外的持久性。这个自我管理的上下文窗口保持代理专注于相关的子集相对溺爱在详尽的但可能不相关的信息。

当然，有一个交换：运行时探索比预计算的数据检索更慢。不仅仅是那样，而是有主见且周到的工程是需要的确保一个LLM具有正确的工具和启发式方法来有效地导航其信息的景观。没有适当的指导，代理能浪费上下文通过工具的误用、追逐死胡同或无法识别关键信息。

在某些设置中，最有效的代理可能使用一个混合策略，检索某数据提前用于速度，并追求进一步的自主探索在其自主。决定边界对于'权利'自主水平的程度取决于任务。Claude Code是一个使用这个混合模型的代理：CLAUDE.md文件是天真地掉进上下文提前，而原始的如glob和grep允许它导航其环境并检索文件及时，有效地绕过过期的索引和复杂句法树的问题。

混合策略对于上下文可能更好地适配较少的动态内容，例如法律或金融工作。随着模型能力改进，代理设计将倾向朝让聪慧的模型聪慧地行动，用逐步较少的人类策划。给予进展的快速速度在该字段中，"做最简单工作的事"将可能保留我们最好的建议对于构建代理的团队顶端Claude。

### 长视野任务的上下文工程

长视野任务需要代理维护连贯性、上下文和目标定向的行为跨行为的序列其中令牌计数超过LLM的上下文窗口。对于任务，其跨越从数十分钟到多个小时的持续工作，如大代码库迁移或全面的研究项目，代理需要专门的技术来围绕上下文窗口大小限制工作。

等待更大的上下文窗口可能似乎像是一个明显的战术。但可能对可预见的未来，所有大小的上下文窗口将受到上下文污染和信息相关性问题——至少对于期望最强代理性能的情形。为了启用代理在扩展的时间视野有效工作，我们已开发了一些技术，其解决这些上下文污染约束直接：压缩、结构化笔记和多代理架构。

**压缩**

压缩是采取逼近上下文窗口限制的一个对话、总结其内容和重新启动一个新上下文窗口与摘要的实践。压缩通常充当上下文工程中驾驭更好的长期连贯性的第一个杠杆。在其核心，压缩用高保真的方式提炼上下文窗口的内容，启用代理继续以最小的性能衰退。

在Claude Code中，例如，我们通过通过模型传递消息历史来实现这个总结其内容并压缩最关键的细节。模型保留了架构的决定、未解决的错误和实现细节，同时抛弃冗余的工具输出或消息。代理然后能继续与这个压缩的上下文加上五个最近被访问的文件。用户得到连贯性而没有担心上下文窗口限制。

压缩的艺术在于什么的选择来保留相对什么来丢弃，如过度激进的压缩能导致其微妙但关键的上下文的损失的重要性只在之后变得明显。对于工程师实施压缩系统，我们推荐在复杂代理追踪中仔细调整你的提示。开始通过最大化回忆确保你的压缩提示捕获来自追踪的每一个相关信息，然后迭代来改进精度通过消除多余的内容。

一个低悬挂的多余内容的例子是清除工具调用和结果——一旦工具已在消息历史中深深被调用，为什么代理需要再次看到原始结果？压缩最安全的最轻接触形式之一是工具结果清除，最近在Claude开发者平台上作为一个特征推出。

**结构化笔记**

结构化的笔记，或代理的记忆，是一个技术其中代理定期写笔记持久到内存之外上下文窗口。这些笔记得到被拉回进入上下文窗口在稍后的时间。

这个策略提供持久的记忆具有最小的开销。如Claude Code创建一个待办事项清单，或你的定制代理维护一个NOTES.md文件，这个简单的模式允许代理跨复杂任务追踪进展，维护关键上下文和依赖关系，其会以其他方式在数打工具调用中丧失。

Claude玩宝可梦展示了记忆在非编码领域如何转换代理能力。代理维护精确的帐目跨数千游戏步骤——追踪目标如"对于过去的1,234步，我一直在Route 1训练我的皮卡丘，皮卡丘已提升了8个级别朝向目标10。"没有任何关于记忆结构的提示，它开发了探索区域的地图，记得它解锁的关键成就，并维护战略笔记的战斗策略帮助它学会哪些攻击对不同对手最有效。

在上下文重置之后，代理读取其自己的笔记并继续多小时的训练序列或地牢探险。这个连贯性跨总结步骤启用长视野策略，其将在完全在LLM的上下文窗口中保留所有信息时是不可能的。

作为我们Sonnet 4.5推出的一部分，我们在公开测试版本上释放了在Claude开发者平台的一个记忆工具，其使得更容易通过一个基于文件的系统存储和咨询信息在外上下文窗口。这允许代理积累知识随时间、跨会话维护项目状态并引用以前的工作而没有在上下文中保留所有事物。

**子代理架构**

子代理架构提供另一个方法围绕上下文限制。而不是一个代理试图维护跨整个项目的状态，专门的子代理能处理专注任务与整洁上下文窗口。主代理与一个高级的计划协调，同时子代理执行深度的技术工作或使用工具来发现相关的信息。每个子代理可能广泛探索，使用数十个数千的令牌或更多，但返回仅一个凝结的、提炼的摘要其工作的（通常是1,000-2,000令牌）。

这个方法达成一个清晰的关注点分离——详细的搜索上下文保留隔离在子代理内，同时主导代理专注于合成和分析结果。这个模式，讨论在我们如何构建我们的多代理研究系统中，显示了对单代理系统在复杂研究任务的实质性改进。

这些方法之间的选择取决于任务特征。例如：

- 压缩维护对话流对于需要广泛的后-和-前来说的任务；
- 笔记采取超越对于迭代开发与清晰的里程碑；
- 多代理架构处理复杂的研究和分析其中平行探索提供红利。

即使随着模型持续改进，维护跨扩展的交互的连贯性的挑战将保持中央对于构建更有效的代理。

### 结论

上下文工程代表了一个我们用LLM构建方式中的根本转变。随着模型变得更有能力，挑战不仅仅是编写完美的提示——这是周到地策划什么信息进入模型的有限注意力预算在每一步。无论你实施了压缩对于长视野任务、设计了令牌高效的工具或启用代理来按需探索他们的环境及时，指导原则保留相同的：发现最小的高信号令牌集合，其最大化你的所需结果的可能性。

我们已列举的技术将继续进化随着模型改进。我们已看到更聪慧的模型需要较少的规定工程，允许代理与更多的自治操作。但即使随着能力缩放，视环境作为一个关键的、有限的资源将保持中央对于构建可靠的、有效的代理。

开始对Claude开发者平台上的上下文工程今天，并通过我们的记忆和上下文管理食谱访问有用的提示和最佳实践。

---

**翻译进度：** 第1-7篇完成 ✓

---

## 第八篇：长时间运行代理的有效束缚

**发布日期：** 2025年11月26日

代理在跨越许多上下文窗口工作时仍然面临挑战。我们查看了人类工程师寻找灵感来为长时间运行代理创建一个更有效的束缚。

随着AI代理变得更有能力，开发者越来越要求他们承担需要工作跨越小时，或甚至天数的复杂任务。但是，获取代理跨多个上下文窗口做出一致的进展保持一个开放的问题。

长时间运行代理的核心挑战是他们必须在离散的会话中工作，每一个新会话以没有先前发生什么的记忆开始。想象一个由工程师在轮班中配备的软件项目，其中每个新工程师到达没有前一个轮班发生什么的记忆。因为上下文窗口是有限的，并因为大多数复杂项目无法在单一窗口中完成，代理需要一个方式来桥接编码会话之间的间隙。

我们开发了一个双折的解决方案来启用Claude代理SDK有效地跨许多上下文窗口工作：一个初始化代理，其在第一个运行上设置环境，以及一个编码代理，其被任务在每一个会话进行增量进展，同时留下清晰的工件对于下一个会话。你能在配套的快速开始中找到代码例子。

### 长时间运行代理问题

Claude代理SDK是一个强大的、通用目的的代理束缚娴熟在编码，同样如也需要模型使用工具来聚集上下文、规划和执行的其他任务。它具有上下文管理能力如压缩，其启用代理在没有耗尽上下文窗口的情形下工作在一个任务上。理论上，给定这个设置，它应该能对代理继续对一个任务做有用的工作对于任意长的时间。

但是，压缩还不足够。开箱即用，甚至一个前沿编码模型如Opus 4.5运行在许多上下文窗口的Claude代理SDK在一个循环中将落短于构建一个生产质量网络应用，如果仅被给了一个高级的提示，例如"构建一个claude.ai的克隆"。

Claude的故障是两个模式中的现实。首先，代理倾向于试图一次做太多——本质上尝试一次射中应用。通常，这导致模型在实现的中间耗尽上下文，留下下一个会话来用一个功能半实现的和无文件的开始。代理然后必须猜到发生了什么，并花费实质的时间试图让基础应用再工作。这发生甚至用压缩，其不总是传递清晰的指令到下一个代理。

一个第二个故障模式会经常后来发生一个项目中。在一些特性已被构建之后，后来代理实例将查看周围，看到进展已被做，并声明工作完成。

这个分解问题为两个部分。首先，我们需要设置一个初始环境，其为所有给定的提示所需的功能奠定基础，其设置代理来逐步工作和特性-由-特性。其次，我们应该提示每一个代理来做朝向其目标的增量进展，同时也留下环境在一个清晰的状态。通过"清晰的状态"我们意思代码将是适当合并到一个主分支的种类：没有主要错误、代码是整洁和文件记录的，一般地说，一个开发者能容易地开始工作在一个新特性而不首先必须清洁一个不相关的混乱。

当进行内部试验时，我们用一个两部分的解决方案处理这些问题：

**初始化代理**：很第一个代理会话使用一个专门的提示，其要求模型设置初始环境：一个init.sh脚本、一个claude-progress.txt文件，保持了代理已做什么的一个日志和一个初始git提交，其显示什么文件被添加。

**编码代理**：每一个后续会话要求模型做增量进展，然后留下结构化的更新。

这里的关键见解是发现一个对代理的方式来快速理解工作的状态当用一个新鲜的上下文窗口开始，其通过claude-progress.txt文件用git历史一起完成。有效的软件工程师日常做的事情启发了这些实践。

### 环境管理

在更新的Claude 4提示指南中，我们分享了多上下文窗口工作流的一些最佳实践，包括一个束缚结构，使用"对于很首先上下文窗口一个不同的提示。"这个"不同的提示"要求初始化代理设置环境用所有必需的上下文，未来的编码代理将需要有效工作。这里，我们提供了对这样一个环境的一些关键组件的一个更深的深入。

**特性列表**

为了处理代理一次射中应用或早期考虑项目完成的问题，我们提示了初始化代理来编写一个基于用户的初始提示展开特性需求的一个综合文件。在claude.ai克隆例子中，这意味着超过200个特性，例如"一个用户能打开一个新聊天、在查询中输入、按进入，并看到AI响应"。这些特性全部最初被标记为"失败"，以便后来的编码代理将具有一个清晰的什么完整功能看起来像的大纲。

```json
{
    "category": "functional",
    "description": "New chat button creates a fresh conversation",
    "steps": [
      "Navigate to main interface",
      "Click the 'New Chat' button",
      "Verify a new conversation is created",
      "Check that chat area shows welcome state",
      "Verify conversation appears in sidebar"
    ],
    "passes": false
}
```

我们提示编码代理来编辑这个文件通过仅改变一个passes字段的状态，并我们使用强词语的指令如"改变或编辑测试是不可接受的，因为这能导致缺失或错误的功能。"在一些试验之后，我们登陆了使用JSON对于这个，因为模型较少可能不适当地改变或覆盖JSON文件相对Markdown文件。

**增量进展**

给定这个初始环境的支架，编码代理的下一个迭代然后被要求在仅一个特性一次工作。这个增量方法证明了对于处理代理的倾向一次做太多是关键。

一旦工作增量，它仍然是至关重要的，模型在做代码改变后留下环境在一个清晰的状态。在我们的试验中，我们发现最好的方式激发这个行为是要求模型以描述性的提交消息提交其进展到git并在一个进展文件中编写摘要。这允许模型使用git来改变回坏代码改变并恢复代码库的工作的状态。

这些方法也增加了效率，因为他们消除了代理必须猜到发生了什么且花时间试图让基础应用再工作的需要。

**测试**

一个我们观察的最后主要的故障模式是Claude的倾向来标记一个特性为完成而没有适当的测试。缺乏明确的提示，Claude倾向于进行代码改变，甚至与单位测试或对一个开发服务器的curl命令进行测试，但将无法认识到特性不工作端到端。

在构建网络应用的实例中，Claude一旦明确被提示来使用浏览器自动化工具并像人类用户会一样进行所有测试主要做得好。

Claude通过Puppeteer MCP服务器拍摄的屏幕截图因为它测试了claude.ai克隆。

提供Claude具有这些测试工具的种类大幅改进了性能，因为代理能够识别和固定错误，其从代码单独不明显。

一些问题保留，如Claude的视觉限制和浏览器自动化工具使得它难以识别每一个类型的错误。例如，Claude不能通过Puppeteer MCP看到浏览器原生警报的模态，并倚赖这些模态的特性倾向于更加多错。

**加速**

具有所有上面的到位，每一个编码代理被提示来运行通过一系列步骤来获得其承认，一些相当基础的但仍然有用：

1. 运行pwd来查看你正在工作的目录。你将仅能编辑这个目录中的文件。
2. 读git日志和进展文件来加速对什么最近被工作在的。
3. 读特性列表文件并选择最高优先级的特性，其尚未完成来工作在。

这个方法节省Claude每一个会话中的一些令牌，因为它不必图表出如何测试代码。它也帮助来要求初始化代理来编写一个init.sh脚本，其能运行开发服务器，然后运行通过一个基本的端到端测试在实施一个新特性之前。

在claude.ai克隆的实例中，这意味着代理总是启动本地开发服务器并使用Puppeteer MCP来启动一个新聊天、发送一个消息和接收响应。这确保Claude能快速识别是否应用被留在一个破坏的状态，并立即固定任何现存的错误。如果代理已代替开始实施一个新特性，它可能使问题更恶劣。

给定所有这个，一个典型的会话开始用以下的助理消息：

```
[助理] I'll start by getting my bearings and understanding the current state of the project.

[工具使用] <bash - pwd>

[工具使用] <read - claude-progress.txt>

[工具使用] <read - feature_list.json>

[助理] Let me check the git log to see recent work.

[工具使用] <bash - git log --oneline -20>

[助理] Now let me check if there's an init.sh script to restart the servers.

<启动开发服务器>

[助理] Excellent! Now let me navigate to the application and verify that some fundamental features are still working.

<测试基本功能>

[助理] Based on my verification testing, I can see that the fundamental functionality is working well. The core chat features, theme switching, conversation loading, and error handling are all functioning correctly. Now let me review the tests.json file more comprehensively to understand what needs to be implemented next.

<开始工作在一个新特性>
```

### 代理故障模式和解决方案

| 问题 | 初始化代理行为 | 编码代理行为 |
|------|---------------|-----------|
| Claude太早在整个项目上声明胜利。 | 设置一个特性列表文件：基于输入规格，设置一个有一个功能需求列表的结构化JSON文件。 | 在会话的开始读特性列表文件。选择一个单一的特性来开始工作在。 |
| Claude留下环境在一个有错误的或无文件进展的状态。 | 一个初始的git仓库和进展笔记文件被编写。 | 通过读进展笔记文件和git提交日志开始会话，并在开发服务器上运行一个基本测试来捕捉任何无文件的错误。以git提交和进展更新结束会话。 |
| Claude标记特性为过早完成。 | 设置一个特性列表文件。 | 自我验证所有特性。仅在仔细测试后标记特性为"传递"。 |
| Claude不得不花时间图表出如何运行应用。 | 编写一个init.sh脚本，其能运行开发服务器。 | 通过读init.sh开始会话。 |

总结四个常见故障模式和长时间运行AI代理中的解决方案。

### 未来工作

这个研究展示了在长时间运行代理束缚中的一个可能的解决方案集合来启用模型跨许多上下文窗口进行增量进展。但是，仍然有开放的问题。

最值得注意的是，它仍然不清楚一个单一的、通用目的的编码代理在上下文中跨表现最好，或如果更好的性能能通过一个多代理架构达成。似乎合理的，专门的代理如一个测试代理、一个质量保证代理或一个代码清洁代理，能在软件开发生命周期中的子任务上做一个甚至更好的工作。

另外，这个演示对完整栈网络应用开发是最优化的。一个未来的方向是概括这些发现到其他字段。可能的一些或所有这些教训能适用到其他类型的长时间运行的代理任务需要的，例如，科学研究或财务建模中。

---

## 总结与反思

这份关于**上下文工程**的完整中文翻译现已完成！

本文档涵盖了8篇来自Anthropic及相关专家的博客文章，深入探讨了如何在AI代理系统中有效地管理上下文窗口。主要内容包括：

### 核心概念：
1. **上下文工程的四大策略**：写入、选择、压缩和隔离
2. **KV缓存优化**对成本和延迟的重要性
3. **工具设计**对代理性能的关键影响
4. **长时间运行代理**的架构设计模式
5. **多代理系统**的并行处理能力

### 实践建议：
- 保持上下文精简但信息密集
- 使用外部存储（文件系统）作为扩展记忆
- 通过结构化笔记和进度追踪维持连贯性
- 优化工具设计以减少上下文消耗
- 在新建大模型前先优化现有系统

**翻译完成日期**：2025年12月30日  
**总字数**：超过 30,000 字  
**全部8篇博客**：✓ 完成

